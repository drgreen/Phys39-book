
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Bayes’ Theorem &#8212; Physics 39 Notes</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Physics 39 Notes</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Welcome to your Jupyter Book
                </a>
            </li>
        </ul>
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="Topic0_Intro.html">
   COGS 18: Introduction to Python
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Topic1a_Data.html">
   Topic 1: Basics of Python
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Topic1b_Functions.html">
   Topic 1b: Functions and Basic Operations
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/executablebooks/jupyter-book/master?urlpath=tree/docs/Topic 6a Bayes' Theorem and Error bars.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/executablebooks/jupyter-book"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2FTopic 6a Bayes' Theorem and Error bars.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="_sources/Topic 6a Bayes' Theorem and Error bars.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Bayes’ Theorem
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#example-hit-by-a-taxi">
     Example: Hit by a Taxi
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#application-coin-flipping">
   Application: coin flipping
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#gaussian-noise">
   Gaussian Noise
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bayesian-inference-for-the-signal">
     Bayesian Inference for the Signal
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#generalizations">
   Generalizations
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#summary">
   Summary
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Bayes’ Theorem</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Bayes’ Theorem
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#example-hit-by-a-taxi">
     Example: Hit by a Taxi
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#application-coin-flipping">
   Application: coin flipping
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#gaussian-noise">
   Gaussian Noise
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bayesian-inference-for-the-signal">
     Bayesian Inference for the Signal
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#generalizations">
   Generalizations
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#summary">
   Summary
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</pre></div>
</div>
</div>
</div>
<section id="bayes-theorem">
<h1>Bayes’ Theorem<a class="headerlink" href="#bayes-theorem" title="Permalink to this headline">#</a></h1>
<p>We have talked about data analysis thus far with using the word “error bar”.  This is a somewhat shocking omision, as data without errors are pretty useless. However, our goal in this course is not just to give you a tool that you don’t understand, but to teach you what the tools are for.  Error bars are an extreme example, as they are both the most important part of any scientific analysis and yet are the piece most likely to be wrong.</p>
<p>A good way understand errors and apply them effectively is to think like a Bayesian.  The reason is that it puts you and your hypotheses right in the middle of the action so that you can see how your choices matter.</p>
<p>To get us started, this is Bayes’ Theorem:
$<span class="math notranslate nohighlight">\(P(H | D) = P(H) P(D|H) / P(D)\)</span><span class="math notranslate nohighlight">\(
Where \)</span>P(H|D)<span class="math notranslate nohighlight">\( is the probability of the Hypothesis (\)</span>H<span class="math notranslate nohighlight">\() given the data (\)</span>D<span class="math notranslate nohighlight">\() and vise versa for \)</span>P(D|H)<span class="math notranslate nohighlight">\(, and \)</span>P(H)<span class="math notranslate nohighlight">\( (\)</span>P(D)$) is the probability of the hypothesis (data).</p>
<p>I always find this very hard to understand.  There are a bunch of variables I don’t know what they mean.  So, let’s think about a simple example:</p>
<section id="example-hit-by-a-taxi">
<h2>Example: Hit by a Taxi<a class="headerlink" href="#example-hit-by-a-taxi" title="Permalink to this headline">#</a></h2>
<p>You live in a place where the are 85 percent green taxis and 15 percent blue taxis.  You got hit by a taxi and a witness claims it was blue.  However, it is determined that eye-witness are accurate about 80 percent of the time and mis-identify the color 20 percent of the time.</p>
<p>So the question is “what is the probability you were hit by a blue cab?”.  So, our hypothesis (<span class="math notranslate nohighlight">\(H\)</span>) is that we you hit by a blue cab and we want to compute <span class="math notranslate nohighlight">\(P(H|D)\)</span>, given the data (<span class="math notranslate nohighlight">\(D\)</span>) that someone saw a blue cab.  If we didn’t know the theorem, what would we do?  We would say, the probably a blue cab was involved, knowing nothing else is 15 percent (<span class="math notranslate nohighlight">\(P(H) =0.15)\)</span>) and the probably that someone would see a blue cab if it was a blue cab is 80 percent (<span class="math notranslate nohighlight">\(P(D|H) = 0.80\)</span>).  The answer is not <span class="math notranslate nohighlight">\(0.15 \times 0.80\)</span> because (1) this makes no sense - even when <span class="math notranslate nohighlight">\(P(D|H) =1\)</span> it gives a small probability and (2) the probabilities of the 2 possibilities don’t add to 1 - <span class="math notranslate nohighlight">\(0.15 \times 0.8 + 0.85 \times 0.2 \neq 1\)</span>.  To normalize our answer correclty, we need to divide by all the different ways we could arrive at the data, namely <span class="math notranslate nohighlight">\(0.15 \times 0.8 + 0.85 \times 0.2\)</span>.  So, our answer is</p>
<div class="math notranslate nohighlight">
\[P(H={\rm blue}|D) = \frac{0.15 \times 0.8}{0.15 \times 0.8 + 0.85 \times 0.2} \sim 0.41\]</div>
<p>Notice that if if the eye witness is perfect (<span class="math notranslate nohighlight">\(P(D|H) = 1\)</span>), our answer is 1, as it should be.</p>
<p>The probability of the data, <span class="math notranslate nohighlight">\(P(D)\)</span>, doesn’t actually depend on the hypothesis: it is a sum over all possibilities.  Its role in life is just to make the probability normalized to one.  To see this, we note that the only two options are that you got hit by a blue taxi or a green taxi.  If we were to now ask “what is the probability you were hit by a green taxi?”, we would have to change <span class="math notranslate nohighlight">\(𝑃(𝐷|𝐻)=0.2\)</span> (there is only a 20% chance that the witness would think it was blue if it was really green) but the probability of the hypothesis itself should <span class="math notranslate nohighlight">\(P(H) = 0.85\)</span> since 85% of taxis are green.  But the probability of the data stays the same, since we already enumated all the possibilities.  This means that
$<span class="math notranslate nohighlight">\(P(H={\rm Green}|D) = \frac{0.2 \times 0.85}{0.15 \times 0.8 + 0.85 \times 0.2} \sim 0.59\)</span><span class="math notranslate nohighlight">\(
Notice that now 
\)</span><span class="math notranslate nohighlight">\(P(H={\rm Green}|D) + P(H={\rm Blue}|D) = 1\)</span><span class="math notranslate nohighlight">\(
This is really what Bayes' theorem is all about: one of the hypotheses must be true, so if \)</span>P(H|D)$ is really a probability, then it must add to up one when we sum over all the possibility.  Bayes’ theorem is just reminding us how to do that.</p>
</section>
</section>
<section id="application-coin-flipping">
<h1>Application: coin flipping<a class="headerlink" href="#application-coin-flipping" title="Permalink to this headline">#</a></h1>
<p>Suppose we have a coin that gives us heads with probability <span class="math notranslate nohighlight">\(p\)</span> and tails with probability <span class="math notranslate nohighlight">\(1-p\)</span> where <span class="math notranslate nohighlight">\(p \in [0,1]\)</span> is unknown to us.  Now I flip the coin <span class="math notranslate nohighlight">\(1000\)</span> times and get <span class="math notranslate nohighlight">\(550\)</span> heads and <span class="math notranslate nohighlight">\(450\)</span> tails.  What do you think <span class="math notranslate nohighlight">\(p\)</span> is?</p>
<p>One way to look at it is to simply simulate what happenss with a fair coin as ask it how often you get 550 heads.  Let’s try 1000 simulations:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">N_sims</span><span class="o">=</span><span class="mi">1000</span>
<span class="n">heads</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">N_sims</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N_sims</span><span class="p">):</span>
    <span class="n">heads</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="n">size</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span><span class="n">ax</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">heads</span><span class="p">,</span><span class="n">bins</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/Topic 6a Bayes' Theorem and Error bars_11_0.png" src="_images/Topic 6a Bayes' Theorem and Error bars_11_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">heads</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>545.0
</pre></div>
</div>
</div>
</div>
<p>Getting 550 heads is possible but very unlikely when <span class="math notranslate nohighlight">\(p=1/2\)</span> (a fair coin).  Instead, let’s apply the machinary of Bayes:</p>
<p>Let’s say we have <span class="math notranslate nohighlight">\(N\)</span> total flips and get <span class="math notranslate nohighlight">\(n\)</span> heads.  The probably of finding <span class="math notranslate nohighlight">\(n\)</span> heads for a given <span class="math notranslate nohighlight">\(p\)</span> gives us the probabability of the data (the likelihood):
$<span class="math notranslate nohighlight">\(P(D | H) = P(n | r) = p^n (1-p)^{N-n} \Big(\frac{N}{n} \Big)\)</span><span class="math notranslate nohighlight">\(
where we have the binomial coefficient \)</span>\Big(\frac{N}{n} \Big)<span class="math notranslate nohighlight">\( which accounts for all the possible ways of getting \)</span>n<span class="math notranslate nohighlight">\( heads (e.g. if you get only \)</span>n=1$, it could have been on the first, second…,last flip of the coin).</p>
<p>We have no idea what the probably of the different models is, so we will assume a flat distribution <span class="math notranslate nohighlight">\(P(p) = \)</span> constant.  Finally, we need to normalize the result by dividing by the integral over <span class="math notranslate nohighlight">\(p\)</span>, such that
$<span class="math notranslate nohighlight">\(P(p| n ) =  p^n (1-p)^{N-n} \Big(\frac{N}{n} \Big) /(\int_0^1 dp p^n (1-p)^{N-n} \Big(\frac{N}{n} \Big))\)</span>$</p>
<p>Let’s apply this to <span class="math notranslate nohighlight">\(N=1000\)</span> and <span class="math notranslate nohighlight">\(n=550\)</span>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">integrate</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">special</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">integrate</span><span class="o">.</span><span class="n">quad</span><span class="p">(</span><span class="k">lambda</span> <span class="n">p</span><span class="p">:</span><span class="n">p</span><span class="o">**</span><span class="p">(</span><span class="mi">550</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">p</span><span class="p">)</span><span class="o">**</span><span class="p">(</span><span class="mi">450</span><span class="p">)</span><span class="o">*</span><span class="n">special</span><span class="o">.</span><span class="n">binom</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span><span class="mi">500</span><span class="p">),</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(0.14876167743337448, 4.263789920566359e-09)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">p_lin</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1000</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span><span class="n">ax</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">6</span><span class="p">),</span><span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">p_lin</span><span class="p">,</span><span class="n">p_lin</span><span class="o">**</span><span class="p">(</span><span class="mi">550</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">p_lin</span><span class="p">)</span><span class="o">**</span><span class="p">(</span><span class="mi">450</span><span class="p">)</span><span class="o">*</span><span class="n">special</span><span class="o">.</span><span class="n">binom</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span><span class="mi">500</span><span class="p">)</span><span class="o">/</span><span class="mf">0.14876167743337448</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">p_lin</span><span class="p">,</span><span class="n">p_lin</span><span class="o">**</span><span class="p">(</span><span class="mi">550</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">p_lin</span><span class="p">)</span><span class="o">**</span><span class="p">(</span><span class="mi">450</span><span class="p">)</span><span class="o">*</span><span class="n">special</span><span class="o">.</span><span class="n">binom</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span><span class="mi">500</span><span class="p">)</span><span class="o">/</span><span class="mf">0.14876167743337448</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span><span class="mf">0.6</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(0.5, 0.6)
</pre></div>
</div>
<img alt="_images/Topic 6a Bayes' Theorem and Error bars_18_1.png" src="_images/Topic 6a Bayes' Theorem and Error bars_18_1.png" />
</div>
</div>
<p>Note: the binomial coefficients are totally unnecessary but they keep us from multiplying and dividing by very small numbers:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">integrate</span><span class="o">.</span><span class="n">quad</span><span class="p">(</span><span class="k">lambda</span> <span class="n">p</span><span class="p">:</span><span class="n">p</span><span class="o">**</span><span class="p">(</span><span class="mi">550</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">p</span><span class="p">)</span><span class="o">**</span><span class="p">(</span><span class="mi">450</span><span class="p">),</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(5.505028184578253e-301, 9.11751014007829e-301)
</pre></div>
</div>
</div>
</div>
<p>Now we can still compare to simulations.  Notice that our distribution is peark at 0.55 =550/1000, so we can simulate <span class="math notranslate nohighlight">\(p=0.55\)</span> and compare to our figure</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">N_sims</span><span class="o">=</span><span class="mi">1000</span>
<span class="n">heads_p</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">N_sims</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N_sims</span><span class="p">):</span>
    <span class="n">heads_p</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">=</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mf">0.55</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">/</span><span class="mf">1000.</span>   
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span><span class="n">ax</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">heads_p</span><span class="p">,</span><span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">p_lin</span><span class="p">,</span><span class="n">p_lin</span><span class="o">**</span><span class="p">(</span><span class="mi">550</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">p_lin</span><span class="p">)</span><span class="o">**</span><span class="p">(</span><span class="mi">450</span><span class="p">)</span><span class="o">*</span><span class="n">special</span><span class="o">.</span><span class="n">binom</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span><span class="mi">500</span><span class="p">)</span><span class="o">/</span><span class="mf">0.14876167743337448</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span><span class="mf">0.6</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(0.5, 0.6)
</pre></div>
</div>
<img alt="_images/Topic 6a Bayes' Theorem and Error bars_23_1.png" src="_images/Topic 6a Bayes' Theorem and Error bars_23_1.png" />
</div>
</div>
</section>
<section id="gaussian-noise">
<h1>Gaussian Noise<a class="headerlink" href="#gaussian-noise" title="Permalink to this headline">#</a></h1>
<p>Now let us return to our previous discussion of data where we had a deterministic model for the signal and a random source of noise
$<span class="math notranslate nohighlight">\( data(t)=S(t) + noise(t)\)</span><span class="math notranslate nohighlight">\( 
The noise is drawn from a Gaussian distribution with a standard deviation \)</span>\sigma$.</p>
<p>It is definitely easier to measure <span class="math notranslate nohighlight">\(S(t)\)</span> if we know what <span class="math notranslate nohighlight">\(\sigma\)</span> is ahead of time.  But how would we know this?  In many cases, we can simply make a measurement when we know there is no signal.  E.g. if you cover up a telescope, then the pictures you take are just the noise of your camera.  By doing this, we get <span class="math notranslate nohighlight">\(N\)</span> measurements drawn from a Gaussian distribution but we don’t know <span class="math notranslate nohighlight">\(\sigma\)</span>.  Now we can use our machinary of Bayesian inference to figure it out.  For each data point, <span class="math notranslate nohighlight">\(n_i\)</span>, the probability of the data, given a <span class="math notranslate nohighlight">\(\sigma\)</span> is
$<span class="math notranslate nohighlight">\(P(n_i) =\frac{\Delta n}{\sqrt{2\pi}\sigma} e^{-n_i^2/(2\sigma^2)}\)</span><span class="math notranslate nohighlight">\( 
where \)</span>\Delta n<span class="math notranslate nohighlight">\( is accuracy with which I measure the noise, i.e. it is the size of the bins in which we group \)</span>n_i$ since we are not measuring to infinite accuracy.</p>
<p>Let’s assume we know thing about <span class="math notranslate nohighlight">\(\sigma\)</span> so that <span class="math notranslate nohighlight">\(P(\sigma) =\)</span> constant, since <span class="math notranslate nohighlight">\(P(D)\)</span> is also just some constant, we can worry about normalization our result later.  Putting this together, we have
$<span class="math notranslate nohighlight">\( P(\sigma | n_i) = \prod_i P(n_i) = \frac{1}{(2\pi)^{N/2} \sigma^N} e^{-(\sum_i n_i^2)/(2\sigma^2)}\)</span>$</p>
<p>We learn wwo things: (1) we recall that <span class="math notranslate nohighlight">\(\sum_i n_i^2 \approx N \bar \sigma^2\)</span> where <span class="math notranslate nohighlight">\(\bar \sigma\)</span> is the true variance.  We can make a figure of this function:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">integrate</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">s</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.6</span><span class="p">,</span><span class="mf">1.4</span><span class="p">,</span><span class="mi">100</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">chiout</span><span class="p">(</span><span class="n">s</span><span class="p">,</span><span class="n">N</span><span class="p">,</span><span class="n">s0</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">const</span><span class="o">=</span><span class="n">integrate</span><span class="o">.</span><span class="n">quad</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">N</span><span class="o">*</span><span class="n">s0</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span><span class="o">/</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">*</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">**</span><span class="p">(</span><span class="n">N</span><span class="p">)),</span><span class="mf">0.2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">limit</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">N</span><span class="o">*</span><span class="n">s0</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">s</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span><span class="o">/</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">*</span><span class="n">s</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">**</span><span class="p">(</span><span class="n">N</span><span class="p">))</span><span class="o">/</span><span class="n">const</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">s</span><span class="p">,</span><span class="n">chiout</span><span class="p">(</span><span class="n">s</span><span class="p">,</span><span class="mi">20</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">s</span><span class="p">,</span><span class="n">chiout</span><span class="p">(</span><span class="n">s</span><span class="p">,</span><span class="mi">80</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">s</span><span class="p">,</span><span class="n">chiout</span><span class="p">(</span><span class="n">s</span><span class="p">,</span><span class="mi">320</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&lt;matplotlib.lines.Line2D at 0x11f62adc0&gt;]
</pre></div>
</div>
<img alt="_images/Topic 6a Bayes' Theorem and Error bars_28_1.png" src="_images/Topic 6a Bayes' Theorem and Error bars_28_1.png" />
</div>
</div>
<p>We see that this follows a familiar pattern: when we increase the amount data by a factor of 4, the width of these curves decreases by a factor of two.  Said differently our error scales as <span class="math notranslate nohighlight">\(1/\sqrt{N}\)</span></p>
<p>(2) we can apply this to data for any <span class="math notranslate nohighlight">\(n_i\)</span> and find the maximum <span class="math notranslate nohighlight">\(\sigma\)</span>. The maximum likelihood will will not necessarily reproduce the one we used to represent the data, but the likelihood should include a reasonably large probability of the true value.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ni</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">chi_data</span><span class="p">(</span><span class="n">s</span><span class="p">,</span><span class="n">n_in</span><span class="p">):</span>
    <span class="n">noise2</span><span class="o">=</span><span class="p">(</span><span class="n">n_in</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="n">N</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">n_in</span><span class="p">)</span>
    <span class="n">const</span><span class="o">=</span><span class="n">integrate</span><span class="o">.</span><span class="n">quad</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">noise2</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span><span class="o">/</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">*</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">**</span><span class="p">(</span><span class="n">N</span><span class="p">)),</span><span class="mf">0.2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">limit</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">const</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">noise2</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">s</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span><span class="o">/</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">*</span><span class="n">s</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">**</span><span class="p">(</span><span class="n">N</span><span class="p">))</span><span class="o">/</span><span class="n">const</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
    <span class="n">ni</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">50</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">s</span><span class="p">,</span><span class="n">chi_data</span><span class="p">(</span><span class="n">s</span><span class="p">,</span><span class="n">ni</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(2.8202541027290504e-29, 2.3476871348758006e-30)
(5.544613008937426e-28, 6.567616823285411e-28)
(1.0680307876759267e-30, 2.333284909696021e-31)
(3.4638652972224263e-31, 1.7178407305523415e-32)
(2.671016175894315e-33, 7.551090842285059e-36)
(1.7219297550232026e-31, 5.092834638341747e-35)
(2.0807772355784533e-34, 1.2367639023531427e-36)
(1.813583328741263e-30, 5.261002919570311e-31)
(1.6945361167301714e-32, 7.530183320608433e-34)
(6.624030273721567e-32, 2.3864747704962663e-33)
</pre></div>
</div>
<img alt="_images/Topic 6a Bayes' Theorem and Error bars_33_1.png" src="_images/Topic 6a Bayes' Theorem and Error bars_33_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
    <span class="n">ni</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">300</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">s</span><span class="p">,</span><span class="n">chi_data</span><span class="p">(</span><span class="n">s</span><span class="p">,</span><span class="n">ni</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(3.644836073098808e-185, 5.6561545714659355e-185)
(3.262214563922754e-197, 3.396174422073964e-197)
(1.2513538412350467e-196, 1.407799968339838e-196)
(8.526626711305601e-190, 1.307420055174152e-189)
(1.7335800121400889e-189, 2.673429963393902e-189)
(1.4476999823446096e-187, 2.2731833466899544e-187)
(4.863037006018032e-176, 7.512798676873814e-176)
(2.480923506579029e-187, 3.8958067970845535e-187)
(1.6836246133242166e-175, 2.5719606018297156e-175)
(1.973677546690494e-186, 3.0930074886356227e-186)
</pre></div>
</div>
<img alt="_images/Topic 6a Bayes' Theorem and Error bars_34_1.png" src="_images/Topic 6a Bayes' Theorem and Error bars_34_1.png" />
</div>
</div>
<p>Of course, we know the maximum of this curve will lie at <span class="math notranslate nohighlight">\(\sigma = \sqrt{\sum n_i^2/N}\)</span>, so we can also just make a histogram of the maximum likelihood points as</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Nsims</span><span class="o">=</span><span class="mi">1000</span>
<span class="n">Ndata</span><span class="o">=</span><span class="mi">100</span>
<span class="n">max_list</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">Nsims</span><span class="p">)</span>
<span class="n">max_list_h</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">Nsims</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">Nsims</span><span class="p">):</span>
    <span class="n">ni</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">Ndata</span><span class="p">)</span>
    <span class="n">max_list</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">((</span><span class="n">ni</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">/</span><span class="n">Ndata</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span><span class="n">ax</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">max_list</span><span class="p">,</span><span class="n">bins</span><span class="o">=</span><span class="mi">40</span><span class="p">)</span>
<span class="n">Ndata</span><span class="o">=</span><span class="mi">400</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">Nsims</span><span class="p">):</span>
    <span class="n">ni</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">Ndata</span><span class="p">)</span>
    <span class="n">max_list_h</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">((</span><span class="n">ni</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">/</span><span class="n">Ndata</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">max_list_h</span><span class="p">,</span><span class="n">bins</span><span class="o">=</span><span class="mi">40</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/Topic 6a Bayes' Theorem and Error bars_36_0.png" src="_images/Topic 6a Bayes' Theorem and Error bars_36_0.png" />
</div>
</div>
<p>We again see that the width of these histograms scales as <span class="math notranslate nohighlight">\(1/\sqrt{N}\)</span>.</p>
<section id="bayesian-inference-for-the-signal">
<h2>Bayesian Inference for the Signal<a class="headerlink" href="#bayesian-inference-for-the-signal" title="Permalink to this headline">#</a></h2>
<p>Taking enough data with no signal, we can determine <span class="math notranslate nohighlight">\(\sigma\)</span> to good enough accuracy that we will assume it is known.  This isn’t always true, but it simplifies how we think about measuring the signal.  We return again to our assumption, but now let’s make it clear that our hypothesis is only about the signal:
$<span class="math notranslate nohighlight">\( data(t|H)=S(t|H) + noise(t)\)</span><span class="math notranslate nohighlight">\( 
However, the only thing that is random is the noise, so the probability of the data is simply:
\)</span><span class="math notranslate nohighlight">\(P(D|H) =\frac{1}{(2\pi)^{N/2} \sigma^N} e^{-(\sum_i (data(t_i) - S(t_i))^2/(2\sigma^2)}\)</span><span class="math notranslate nohighlight">\(
This is literally just the same equation we had before since \)</span>data_i -S_i =n_i<span class="math notranslate nohighlight">\(.  However, now our posterior is for the parameters of our model, rather than \)</span>\sigma$.</p>
<p>Let’s see how this works for a line with noise:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">trange</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">1000</span><span class="p">)</span>
<span class="n">data_t</span><span class="o">=</span><span class="mf">0.07</span><span class="o">*</span><span class="n">trange</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">Pos_line</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">,</span><span class="n">t</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">noise2</span><span class="o">=</span><span class="p">((</span><span class="n">data</span><span class="o">-</span><span class="n">a</span><span class="o">*</span><span class="n">t</span><span class="o">-</span><span class="n">b</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">noise2</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">s</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">a_r</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mf">0.12</span><span class="p">,</span><span class="mi">100</span><span class="p">)</span>
<span class="n">Pos_r</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">Pos_r</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">=</span><span class="n">Pos_line</span><span class="p">(</span><span class="n">data_t</span><span class="p">,</span><span class="n">a_r</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="mi">0</span><span class="p">,</span><span class="n">trange</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">a_r</span><span class="p">,</span><span class="n">Pos_r</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/Topic 6a Bayes' Theorem and Error bars_43_0.png" src="_images/Topic 6a Bayes' Theorem and Error bars_43_0.png" />
</div>
</div>
<p>We notice the very small size of the posterior here, because I didn’t bother to normal by dividing by <span class="math notranslate nohighlight">\(P(D)\)</span>. In practice, we we need to know about the postior is just the maximum likelihood point and <span class="math notranslate nohighlight">\(1\sigma\)</span>, <span class="math notranslate nohighlight">\(2\sigma\)</span>, <span class="math notranslate nohighlight">\(3\sigma\)</span> lines. However for this we don’t actually need to work with the full posterior.  Instead we can take the log:
$<span class="math notranslate nohighlight">\(-2\log P(H,D) = \sum_i (data(t_i) - S(t_i))^2/(\sigma^2) +{\rm constant} \)</span><span class="math notranslate nohighlight">\(
We see that minimizing \)</span>-\log P(H,D)<span class="math notranslate nohighlight">\( is exactly the same quantity we minimized in finding our best fit curves.  Now suppose that in the vacinity of the maximum likelihood point for a parameter of our model, \)</span>a<span class="math notranslate nohighlight">\( we have
\)</span><span class="math notranslate nohighlight">\( -\log P(H,D) \approx -\frac{(a-a_{\rm min})^2}{2 \sigma_a^2}\)</span><span class="math notranslate nohighlight">\(
Then when \)</span>a = a_{\rm min} + n \sigma_a<span class="math notranslate nohighlight">\( we have \)</span>-2\log P(H,D) = -2\log P(H,D)|<em>{a</em>{\rm min}}+ n^2$</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">chi_line</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">,</span><span class="n">t</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">noise2</span><span class="o">=</span><span class="p">((</span><span class="n">data</span><span class="o">-</span><span class="n">a</span><span class="o">*</span><span class="n">t</span><span class="o">-</span><span class="n">b</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">noise2</span><span class="o">/</span><span class="p">(</span><span class="n">s</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">chi_r</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">chi_r</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">=</span><span class="n">chi_line</span><span class="p">(</span><span class="n">data_t</span><span class="p">,</span><span class="n">a_r</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="mi">0</span><span class="p">,</span><span class="n">trange</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">a_r</span><span class="p">,</span><span class="n">chi_r</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/Topic 6a Bayes' Theorem and Error bars_46_0.png" src="_images/Topic 6a Bayes' Theorem and Error bars_46_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="kn">import</span> <span class="n">minimize</span>
<span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="kn">import</span> <span class="n">newton</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">a_min_loc</span><span class="o">=</span><span class="n">minimize</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">chi_line</span><span class="p">(</span><span class="n">data_t</span><span class="p">,</span><span class="n">x</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="n">trange</span><span class="p">),</span><span class="mf">0.070</span><span class="p">)[</span><span class="s1">&#39;x&#39;</span><span class="p">]</span>
<span class="n">minimize</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">chi_line</span><span class="p">(</span><span class="n">data_t</span><span class="p">,</span><span class="n">x</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="n">trange</span><span class="p">),</span><span class="mf">0.070</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>      fun: 968.2312380853981
 hess_inv: array([[1]])
      jac: array([-7.62939453e-06])
  message: &#39;Optimization terminated successfully.&#39;
     nfev: 6
      nit: 1
     njev: 3
   status: 0
  success: True
        x: array([0.07408579])
</pre></div>
</div>
</div>
</div>
<p>Having found the location of the minimum, we now proceed to find the value of the minimum and the location of the <span class="math notranslate nohighlight">\(1\sigma\)</span> and <span class="math notranslate nohighlight">\(2\sigma\)</span> contours:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">chi_min</span><span class="o">=</span><span class="n">chi_line</span><span class="p">(</span><span class="n">data_t</span><span class="p">,</span><span class="n">a_min_loc</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="n">trange</span><span class="p">)</span>
<span class="n">Pos_max</span><span class="o">=</span><span class="n">Pos_line</span><span class="p">(</span><span class="n">data_t</span><span class="p">,</span><span class="n">a_min_loc</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="n">trange</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">chi_min</span><span class="p">,</span><span class="n">Pos_max</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>968.2312380853981 5.639726542964792e-211
</pre></div>
</div>
</div>
</div>
<p>The <span class="math notranslate nohighlight">\(1\sigma\)</span> lines are the minimum <span class="math notranslate nohighlight">\(\chi^2 +1\)</span></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">s1L</span><span class="o">=</span><span class="n">newton</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">chi_line</span><span class="p">(</span><span class="n">data_t</span><span class="p">,</span><span class="n">x</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="n">trange</span><span class="p">)</span><span class="o">-</span><span class="n">chi_min</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mf">0.065</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">s1L</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.06860993915478424
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">s1R</span><span class="o">=</span><span class="n">newton</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">chi_line</span><span class="p">(</span><span class="n">data_t</span><span class="p">,</span><span class="n">x</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="n">trange</span><span class="p">)</span><span class="o">-</span><span class="n">chi_min</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mf">0.08</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">s1R</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.0795616499795171
</pre></div>
</div>
</div>
</div>
<p>The <span class="math notranslate nohighlight">\(2\sigma\)</span> lines are the minimum <span class="math notranslate nohighlight">\(\chi^2 +2\)</span></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">s2L</span><span class="o">=</span><span class="n">newton</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">chi_line</span><span class="p">(</span><span class="n">data_t</span><span class="p">,</span><span class="n">x</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="n">trange</span><span class="p">)</span><span class="o">-</span><span class="n">chi_min</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span><span class="mf">0.065</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">s2L</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.0631340837425053
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">s2R</span><span class="o">=</span><span class="n">newton</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">chi_line</span><span class="p">(</span><span class="n">data_t</span><span class="p">,</span><span class="n">x</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="n">trange</span><span class="p">)</span><span class="o">-</span><span class="n">chi_min</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span><span class="mf">0.08</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">s2R</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.08503750539148103
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">chi_min</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>968.2312380853981
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span><span class="n">ax</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">6</span><span class="p">),</span><span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">a_r</span><span class="p">,</span><span class="n">chi_r</span><span class="p">,</span><span class="n">lw</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">s1L</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">),[</span><span class="n">chi_min</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="n">chi_min</span><span class="o">+</span><span class="mi">10</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;darkorange&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">s1R</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">),[</span><span class="n">chi_min</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="n">chi_min</span><span class="o">+</span><span class="mi">10</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;darkorange&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">s2L</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">),[</span><span class="n">chi_min</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="n">chi_min</span><span class="o">+</span><span class="mi">10</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;darkblue&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">s2R</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">),[</span><span class="n">chi_min</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="n">chi_min</span><span class="o">+</span><span class="mi">10</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;darkblue&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mf">0.055</span><span class="p">,</span><span class="mf">0.09</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="n">chi_min</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="n">chi_min</span><span class="o">+</span><span class="mi">10</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">a_r</span><span class="p">,</span><span class="n">Pos_r</span><span class="o">/</span><span class="n">Pos_max</span><span class="p">,</span><span class="n">lw</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">s1L</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">),[</span><span class="mi">0</span><span class="p">,</span><span class="mf">1.1</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;darkorange&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">s1R</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">),[</span><span class="mi">0</span><span class="p">,</span><span class="mf">1.1</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;darkorange&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">s2L</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">),[</span><span class="mi">0</span><span class="p">,</span><span class="mf">1.1</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;darkblue&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">s2R</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">),[</span><span class="mi">0</span><span class="p">,</span><span class="mf">1.1</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;darkblue&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mf">0.055</span><span class="p">,</span><span class="mf">0.09</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mf">1.1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/Topic 6a Bayes' Theorem and Error bars_58_0.png" src="_images/Topic 6a Bayes' Theorem and Error bars_58_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">a_min_loc</span><span class="o">-</span><span class="n">s1L</span><span class="p">,</span><span class="n">s1R</span><span class="o">-</span><span class="n">a_min_loc</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">a_min_loc</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[0.00547585] [0.00547586]
[0.07408579]
</pre></div>
</div>
</div>
</div>
<p>At <span class="math notranslate nohighlight">\(1\sigma\)</span>, we have determined that <span class="math notranslate nohighlight">\(a = a_{\rm min} \pm 0.0055\)</span></p>
<p>Now, our line is really a two dimensional space, not a one dimensional space. In this case we have two options: (1) we want to know the multi-dimensional behavior (make a contour plot) or (2) we average over a parameter we don’t care about (marginalize).</p>
<p>First, let us repeat what we did above but now using the model <span class="math notranslate nohighlight">\(S(t|a,b)= a t+b\)</span>.  First we find the minimum</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">minimize</span><span class="p">(</span><span class="k">lambda</span> <span class="n">X</span><span class="p">:</span><span class="n">chi_line</span><span class="p">(</span><span class="n">data_t</span><span class="p">,</span><span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">X</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">trange</span><span class="p">),[</span><span class="mf">0.07</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span><span class="n">method</span><span class="o">=</span><span class="s1">&#39;Nelder-Mead&#39;</span><span class="p">,</span><span class="n">tol</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> final_simplex: (array([[ 0.08315065, -0.06046261],
       [ 0.08315072, -0.06046346],
       [ 0.08315061, -0.06046289]]), array([967.31591458, 967.31591458, 967.31591458]))
           fun: 967.3159145823855
       message: &#39;Optimization terminated successfully.&#39;
          nfev: 102
           nit: 55
        status: 0
       success: True
             x: array([ 0.08315065, -0.06046261])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">line_sol</span><span class="o">=</span><span class="n">minimize</span><span class="p">(</span><span class="k">lambda</span> <span class="n">X</span><span class="p">:</span><span class="n">chi_line</span><span class="p">(</span><span class="n">data_t</span><span class="p">,</span><span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">X</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">trange</span><span class="p">),[</span><span class="mf">0.07</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span><span class="n">method</span><span class="o">=</span><span class="s1">&#39;Nelder-Mead&#39;</span><span class="p">,</span><span class="n">tol</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">)[</span><span class="s1">&#39;x&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>It might seem a bit surprising that when we fit the line, the best fit value of <span class="math notranslate nohighlight">\(a\)</span> is quite far from our best fit result.  Concretely, when we set <span class="math notranslate nohighlight">\(b=0\)</span>, we got <span class="math notranslate nohighlight">\(a\sim 0.07 \pm 0.055\)</span> and now our best fit <span class="math notranslate nohighlight">\(a\)</span> looks like it is more than 2<span class="math notranslate nohighlight">\(\sigma\)</span> off.  We can check that the line is a good fit to the data</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">trange</span><span class="p">,</span><span class="n">data_t</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">trange</span><span class="p">,</span><span class="n">line_sol</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">trange</span><span class="o">+</span><span class="n">line_sol</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">lw</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;darkorange&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">trange</span><span class="p">,</span><span class="mf">0.07</span><span class="o">*</span><span class="n">trange</span><span class="p">,</span><span class="n">lw</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;darkred&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/Topic 6a Bayes' Theorem and Error bars_66_0.png" src="_images/Topic 6a Bayes' Theorem and Error bars_66_0.png" />
</div>
</div>
<p>Now let’s understand what is going on by making a figure of the 2D posterior.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">chi_min_line</span><span class="o">=</span><span class="n">chi_line</span><span class="p">(</span><span class="n">data_t</span><span class="p">,</span><span class="n">line_sol</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">line_sol</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">trange</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">chi_min_line</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>967.3159145823855
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">b_r</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="mf">0.5</span><span class="p">,</span><span class="mi">100</span><span class="p">)</span>
<span class="n">A</span><span class="p">,</span><span class="n">B</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">a_r</span><span class="p">,</span><span class="n">b_r</span><span class="p">)</span>
<span class="n">logP</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
        <span class="n">logP</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span><span class="o">=</span><span class="n">chi_line</span><span class="p">(</span><span class="n">data_t</span><span class="p">,</span><span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">],</span><span class="n">B</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">],</span><span class="n">trange</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>In order to choose contours, we need to know the values of <span class="math notranslate nohighlight">\(\chi^2\)</span> that correspond the 1<span class="math notranslate nohighlight">\(\sigma\)</span> (~68%) and <span class="math notranslate nohighlight">\(2\sigma\)</span>(~95%) confidence regions (i.e. you have the same probability of finding the true mode there as if it was a <span class="math notranslate nohighlight">\(1\sigma\)</span> or <span class="math notranslate nohighlight">\(2\sigma\)</span> line for a Gaussian.  For a 2 dimensional space, the answer is 2.3 and 6.18 so we make the contours as:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span><span class="n">ax</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">contour</span><span class="p">(</span><span class="n">A</span><span class="p">,</span><span class="n">B</span><span class="p">,</span><span class="n">logP</span><span class="p">,</span><span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;RdBu&#39;</span><span class="p">,</span><span class="n">levels</span><span class="o">=</span><span class="p">[</span><span class="n">chi_min_line</span><span class="o">+</span><span class="mf">2.30</span><span class="p">,</span><span class="n">chi_min_line</span><span class="o">+</span><span class="mf">6.18</span><span class="p">])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="mf">0.07</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;darkred&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">s1L</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">b_r</span><span class="p">)),</span><span class="n">b_r</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;darkorange&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">s1R</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">b_r</span><span class="p">)),</span><span class="n">b_r</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;darkorange&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">s2L</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">b_r</span><span class="p">)),</span><span class="n">b_r</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;darkblue&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">s2R</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">b_r</span><span class="p">)),</span><span class="n">b_r</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;darkblue&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/Topic 6a Bayes' Theorem and Error bars_71_0.png" src="_images/Topic 6a Bayes' Theorem and Error bars_71_0.png" />
</div>
</div>
<p>This figure reveals that it is pretty hard to tell apart <span class="math notranslate nohighlight">\(a\)</span> and <span class="math notranslate nohighlight">\(b\)</span>.  When we include the possibility of <span class="math notranslate nohighlight">\(b\neq 0\)</span>, we see that the allowed values of <span class="math notranslate nohighlight">\(a\)</span> cover a much larger region compared to the lines that show the 1<span class="math notranslate nohighlight">\(\sigma\)</span> and 2<span class="math notranslate nohighlight">\(\sigma\)</span> lines we found when <span class="math notranslate nohighlight">\(b=0\)</span>.</p>
<p>We can also look at this in terms of the posterior for <span class="math notranslate nohighlight">\(a\)</span> ignoring <span class="math notranslate nohighlight">\(b\)</span>.  Rather than a conditional probability for the pair <span class="math notranslate nohighlight">\((a,b)\)</span> we just want to know the probability of <span class="math notranslate nohighlight">\(a\)</span> including all possible <span class="math notranslate nohighlight">\(b\)</span> values.</p>
<p>We can think of this like we are flipping a pair of coins and we want to count how often they match.  We have to add up all the cases where you get two heads or two tails, even though we know they are different.  We are doing the same here, we are going to add up all pairs of <span class="math notranslate nohighlight">\((a,b)\)</span> that have the same value of <span class="math notranslate nohighlight">\(a\)</span>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">chi_marg</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="n">a</span><span class="p">,</span><span class="n">t</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">Mar_pos</span><span class="o">=</span><span class="n">integrate</span><span class="o">.</span><span class="n">quad</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">Pos_line</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="n">a</span><span class="p">,</span><span class="n">x</span><span class="p">,</span><span class="n">t</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">return</span> <span class="o">-</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">Mar_pos</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">chi_marg</span><span class="p">(</span><span class="n">data_t</span><span class="p">,</span><span class="mf">0.07</span><span class="p">,</span><span class="n">trange</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>973.8299138430693
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">chi_mar_out</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">a_r</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">a_r</span><span class="p">)):</span>
    <span class="n">chi_mar_out</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">=</span><span class="n">chi_marg</span><span class="p">(</span><span class="n">data_t</span><span class="p">,</span><span class="n">a_r</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">trange</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">a_r</span><span class="p">,</span><span class="n">chi_mar_out</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&lt;matplotlib.lines.Line2D at 0x11f3cc820&gt;]
</pre></div>
</div>
<img alt="_images/Topic 6a Bayes' Theorem and Error bars_77_1.png" src="_images/Topic 6a Bayes' Theorem and Error bars_77_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">a_min_marg</span><span class="o">=</span><span class="n">minimize</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">chi_marg</span><span class="p">(</span><span class="n">data_t</span><span class="p">,</span><span class="n">x</span><span class="p">,</span><span class="n">trange</span><span class="p">),</span><span class="mf">0.080</span><span class="p">,</span><span class="n">method</span><span class="o">=</span><span class="s1">&#39;Nelder-Mead&#39;</span><span class="p">,</span><span class="n">tol</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">)[</span><span class="s1">&#39;x&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">chi_min_marg</span><span class="o">=</span><span class="n">chi_marg</span><span class="p">(</span><span class="n">data_t</span><span class="p">,</span><span class="n">a_min_marg</span><span class="p">,</span><span class="n">trange</span><span class="p">)</span>    
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">s1L_marg</span><span class="o">=</span><span class="n">newton</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">chi_marg</span><span class="p">(</span><span class="n">data_t</span><span class="p">,</span><span class="n">x</span><span class="p">,</span><span class="n">trange</span><span class="p">)</span><span class="o">-</span><span class="n">chi_min_marg</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mf">0.07</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">s1L_marg</span><span class="p">)</span>
<span class="n">s1R_marg</span><span class="o">=</span><span class="n">newton</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">chi_marg</span><span class="p">(</span><span class="n">data_t</span><span class="p">,</span><span class="n">x</span><span class="p">,</span><span class="n">trange</span><span class="p">)</span><span class="o">-</span><span class="n">chi_min_marg</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mf">0.09</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">s1R_marg</span><span class="p">)</span>
<span class="n">s2L_marg</span><span class="o">=</span><span class="n">newton</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">chi_marg</span><span class="p">(</span><span class="n">data_t</span><span class="p">,</span><span class="n">x</span><span class="p">,</span><span class="n">trange</span><span class="p">)</span><span class="o">-</span><span class="n">chi_min_marg</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span><span class="mf">0.07</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">s2L_marg</span><span class="p">)</span>
<span class="n">s2R_marg</span><span class="o">=</span><span class="n">newton</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">chi_marg</span><span class="p">(</span><span class="n">data_t</span><span class="p">,</span><span class="n">x</span><span class="p">,</span><span class="n">trange</span><span class="p">)</span><span class="o">-</span><span class="n">chi_min_marg</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span><span class="mf">0.09</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">s2R_marg</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.07220469464134953
0.09407763827474096
0.06126279694454297
0.10501661076526125
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span><span class="n">ax</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">a_r</span><span class="p">,</span><span class="n">chi_mar_out</span><span class="p">,</span><span class="n">lw</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">a_r</span><span class="p">,</span><span class="n">chi_r</span><span class="p">,</span><span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;indigo&#39;</span><span class="p">,</span><span class="n">ls</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">s1L_marg</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">),[</span><span class="n">chi_min_marg</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span><span class="n">chi_min_marg</span><span class="o">+</span><span class="mi">10</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;darkorange&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">s1R_marg</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">),[</span><span class="n">chi_min_marg</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span><span class="n">chi_min_marg</span><span class="o">+</span><span class="mi">10</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;darkorange&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">s2L_marg</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">),[</span><span class="n">chi_min_marg</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span><span class="n">chi_min_marg</span><span class="o">+</span><span class="mi">10</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;darkblue&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">s2R_marg</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">),[</span><span class="n">chi_min_marg</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span><span class="n">chi_min_marg</span><span class="o">+</span><span class="mi">10</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;darkblue&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mf">0.055</span><span class="p">,</span><span class="mf">0.12</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="n">chi_min_marg</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span><span class="n">chi_min_marg</span><span class="o">+</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(968.3863090416023, 982.3863090416023)
</pre></div>
</div>
<img alt="_images/Topic 6a Bayes' Theorem and Error bars_81_1.png" src="_images/Topic 6a Bayes' Theorem and Error bars_81_1.png" />
</div>
</div>
</section>
</section>
<section id="generalizations">
<h1>Generalizations<a class="headerlink" href="#generalizations" title="Permalink to this headline">#</a></h1>
<p><strong>Priors</strong> Notice that the marginalized likelihood is much wider than the one where <span class="math notranslate nohighlight">\(b=0\)</span>.  This makes sense, because forcing <span class="math notranslate nohighlight">\(b=0\)</span> is some kind of extra knowledge we used.</p>
<p>We can make sense of this using the idea of a prior, <span class="math notranslate nohighlight">\(P(H)\)</span>.  Specifically, the two extremes we have considered are just limits of the prior
$<span class="math notranslate nohighlight">\(P(b) =\frac{1}{\sqrt{2\pi \sigma_b^2}} e^{-b^2/(2 \sigma_b^2)} \)</span><span class="math notranslate nohighlight">\(
When \)</span>\sigma_b \to 0<span class="math notranslate nohighlight">\(, we recover the case where \)</span>b=0<span class="math notranslate nohighlight">\( and when \)</span>\sigma_b \to \infty<span class="math notranslate nohighlight">\( we recover a flat prior on \)</span>b$.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">chi_marg_prior</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="n">a</span><span class="p">,</span><span class="n">t</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">b</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="n">sb</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">Mar_pos</span><span class="o">=</span><span class="n">integrate</span><span class="o">.</span><span class="n">quad</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">Pos_line</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="n">a</span><span class="p">,</span><span class="n">x</span><span class="p">,</span><span class="n">t</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="n">b</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">sb</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span><span class="o">/</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">*</span><span class="n">sb</span><span class="o">**</span><span class="mi">2</span><span class="p">)),</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">epsabs</span><span class="o">=</span><span class="mf">1.49e-16</span><span class="p">,</span> <span class="n">epsrel</span><span class="o">=</span><span class="mf">1.49e-16</span><span class="p">,</span> <span class="n">limit</span><span class="o">=</span><span class="mi">10000</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">return</span> <span class="o">-</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">Mar_pos</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">chi_prior</span><span class="o">=</span><span class="p">{}</span>
<span class="n">sig_b</span><span class="o">=</span><span class="p">[</span><span class="mf">0.3</span><span class="p">,</span><span class="mf">0.1</span><span class="p">,</span><span class="mf">0.03</span><span class="p">,</span><span class="mf">0.01</span><span class="p">]</span>
<span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">sig_b</span><span class="p">:</span>
    <span class="n">chi_prior</span><span class="p">[</span><span class="n">s</span><span class="p">]</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">a_r</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">a_r</span><span class="p">)):</span>
    <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">sig_b</span><span class="p">:</span>
        <span class="n">chi_prior</span><span class="p">[</span><span class="n">s</span><span class="p">][</span><span class="n">i</span><span class="p">]</span><span class="o">=</span><span class="n">chi_marg_prior</span><span class="p">(</span><span class="n">data_t</span><span class="p">,</span><span class="n">a_r</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">trange</span><span class="p">,</span><span class="n">sb</span><span class="o">=</span><span class="n">s</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span><span class="n">ax</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
<span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">sig_b</span><span class="p">:</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">a_r</span><span class="p">,</span><span class="n">chi_prior</span><span class="p">[</span><span class="n">s</span><span class="p">],</span><span class="n">label</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span><span class="n">s</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">a_r</span><span class="p">,</span><span class="n">chi_r</span><span class="p">,</span><span class="n">ls</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/Topic 6a Bayes' Theorem and Error bars_86_0.png" src="_images/Topic 6a Bayes' Theorem and Error bars_86_0.png" />
</div>
</div>
<p>We see in this way what priors are doing for us: they are making it clear how to go between modes with more parameters and less parameters.  Reducing the number of parameters is an extreme version of adding information about parameters in the form of a prior.</p>
<p>However, as we will see in the next topic, there is a reason we don’t just add models with lots of parameters and lots of priors when we don’t need to: this integral to marginalize of <span class="math notranslate nohighlight">\(b\)</span> becomes very challenging very quickly.</p>
<p><strong>Non-uniform Errors</strong> So far we have been treating the error (std deviation of the noise) <span class="math notranslate nohighlight">\(\sigma\)</span> as constant. When doing this, we saw that finding the maximum value of the posterior was the same the least squares fit that is typical of linear regression algorithms.</p>
<p>However, it is not true that the error in most data is uniform. For example, we might want to combine data taken at different times or with different detectors where the noise.  However, in many of these cases, we still understand the noise well enough to treak <span class="math notranslate nohighlight">\(\sigma\)</span> as a known quantity.</p>
<p>We can easily adjust our model to include this option</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">chi_line_s</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">,</span><span class="n">t</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">noise2</span><span class="o">=</span><span class="p">((</span><span class="n">data</span><span class="o">-</span><span class="n">a</span><span class="o">*</span><span class="n">t</span><span class="o">-</span><span class="n">b</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="p">(</span><span class="n">s</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">noise2</span>
</pre></div>
</div>
</div>
</div>
<p>This still has <span class="math notranslate nohighlight">\(s=1\)</span> as a default, but let’s put in <span class="math notranslate nohighlight">\(s\)</span> is a decreasing function of time for both the data and our chi</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data_s</span><span class="o">=</span><span class="mf">0.07</span><span class="o">*</span><span class="n">trange</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="mf">0.1</span><span class="o">+</span><span class="p">(</span><span class="n">trange</span><span class="o">-</span><span class="mi">5</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="mi">25</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">s_r</span><span class="o">=</span><span class="p">(</span><span class="mf">0.1</span><span class="o">+</span><span class="p">(</span><span class="n">trange</span><span class="o">-</span><span class="mi">5</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="mi">25</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">chi_line_s</span><span class="p">(</span><span class="n">data_s</span><span class="p">,</span><span class="mf">0.07</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="n">trange</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="n">s_r</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>923.6038757139302
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">a_min_loc_s</span><span class="o">=</span><span class="n">minimize</span><span class="p">(</span><span class="k">lambda</span> <span class="n">X</span><span class="p">:</span><span class="n">chi_line_s</span><span class="p">(</span><span class="n">data_s</span><span class="p">,</span><span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">X</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">trange</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="n">s_r</span><span class="p">),[</span><span class="mf">0.070</span><span class="p">,</span><span class="mi">0</span><span class="p">])[</span><span class="s1">&#39;x&#39;</span><span class="p">]</span>
<span class="n">a_min_loc_wrong</span><span class="o">=</span><span class="n">minimize</span><span class="p">(</span><span class="k">lambda</span> <span class="n">X</span><span class="p">:</span><span class="n">chi_line</span><span class="p">(</span><span class="n">data_s</span><span class="p">,</span><span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">X</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">trange</span><span class="p">),[</span><span class="mf">0.070</span><span class="p">,</span><span class="mi">0</span><span class="p">])[</span><span class="s1">&#39;x&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">trange</span><span class="p">,</span><span class="n">data_s</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">trange</span><span class="p">,</span><span class="n">a_min_loc_s</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">trange</span><span class="o">+</span><span class="n">a_min_loc_s</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">trange</span><span class="p">,</span><span class="n">a_min_loc_wrong</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">trange</span><span class="o">+</span><span class="n">a_min_loc_wrong</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;module &#39;matplotlib.pyplot&#39; from &#39;/opt/anaconda3/lib/python3.9/site-packages/matplotlib/pyplot.py&#39;&gt;
</pre></div>
</div>
<img alt="_images/Topic 6a Bayes' Theorem and Error bars_95_1.png" src="_images/Topic 6a Bayes' Theorem and Error bars_95_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">a_min_loc_wrong</span><span class="p">,</span><span class="n">a_min_loc_s</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(array([0.0655701 , 0.01624252]), array([0.06454917, 0.02504711]))
</pre></div>
</div>
</div>
</div>
<p>Although the lines look similar, we see that weighting the data with the correct noise model gave a much better fit in terms of being much close to the true value.  Furthermore, we also know that it would make no sense to report undercertainties on our least squares fit, as the errors only make sense when you know <span class="math notranslate nohighlight">\(\sigma(t)\)</span>.</p>
</section>
<section id="summary">
<h1>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">#</a></h1>
<p>Bayesian inference is argueably the most important framework in which to understand data, whether scientific or otherwise.  With very little work, we could understand a lot of seemingly complicated statistical tools as just examples of Bayes’ theorem in special cases. Most important, the concept of uncertainty is essential when trying to understand the world: our knownledge isn’t binary, but comes with levels of confidence.  Bayes’ tells us how to make that uncertainty precise and do work for us.</p>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By The Jupyter Book Community<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>