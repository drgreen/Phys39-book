
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Topic 6a: Bayes‚Äô Theorem &#8212; Physics 39 Notes</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Topic 6b: Intro to Machine Learning" href="Topic6b_ML.html" />
    <link rel="prev" title="Topic 5: Intro to Data Analysis" href="Topic5_data_analysis.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Physics 39 Notes</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Physics 39: Scientific Computing with Python
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="Topic0_Intro.html">
   Physics 39: Scientific Computing with Python
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Topic1a_Data.html">
   Topic 1a: Basics of Python
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Topic1b_Functions.html">
   Topic 1b: Functions and Basic Operations
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Topic2a_numpy.html">
   Topic 2a:  numpy
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Topic2b_random.html">
   Topic 2b: Mathematical Operations in Numpy
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Topic3_Matplotlib.html">
   Topic3: Plotting and Data Visualization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Topic4b_Integration.html">
   Topic 4b: Integration
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Topic4c_ODEs.html">
   Topic 4c: Solving Ordinary Differential Equations
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Topic5_data_analysis.html">
   Topic 5: Intro to Data Analysis
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Topic 6a: Bayes‚Äô Theorem
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Topic6b_ML.html">
   Topic 6b: Intro to Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Topic6c_MC.html">
   Topic 6c: Monte Carlo Methods
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Topic6d_Sympy.html">
   Topic 6d: Symbolic Computing
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/executablebooks/jupyter-book/master?urlpath=tree/docs/Topic6a_Bayes.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/executablebooks/jupyter-book"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2FTopic6a_Bayes.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="_sources/Topic6a_Bayes.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#example-hit-by-a-taxi">
   Example: Hit by a Taxi
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#application-coin-flipping">
   Application: coin flipping
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#gaussian-noise">
   Gaussian Noise
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bayesian-inference-for-the-signal">
     Bayesian Inference for the Signal
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#generalizations">
   Generalizations
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#summary">
   Summary
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Topic 6a: Bayes‚Äô Theorem</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#example-hit-by-a-taxi">
   Example: Hit by a Taxi
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#application-coin-flipping">
   Application: coin flipping
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#gaussian-noise">
   Gaussian Noise
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bayesian-inference-for-the-signal">
     Bayesian Inference for the Signal
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#generalizations">
   Generalizations
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#summary">
   Summary
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="topic-6a-bayes-theorem">
<h1>Topic 6a: Bayes‚Äô Theorem<a class="headerlink" href="#topic-6a-bayes-theorem" title="Permalink to this headline">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</pre></div>
</div>
</div>
</div>
<p>We have talked about data analysis thus far with using the word ‚Äúerror bar‚Äù.  This is a somewhat shocking omision, as data without errors are pretty useless. However, our goal in this course is not just to give you a tool that you don‚Äôt understand, but to teach you what the tools are for.  Error bars are an extreme example, as they are both the most important part of any scientific analysis and yet are the piece most likely to be wrong.</p>
<p>A good way understand errors and apply them effectively is to think like a Bayesian.  The reason is that it puts you and your hypotheses right in the middle of the action so that you can see how your choices matter.</p>
<p>To get us started, this is Bayes‚Äô Theorem:
$<span class="math notranslate nohighlight">\(P(H | D) = P(H) P(D|H) / P(D)\)</span><span class="math notranslate nohighlight">\(
Where \)</span>P(H|D)<span class="math notranslate nohighlight">\( is the probability of the Hypothesis (\)</span>H<span class="math notranslate nohighlight">\() given the data (\)</span>D<span class="math notranslate nohighlight">\() and vise versa for \)</span>P(D|H)<span class="math notranslate nohighlight">\(, and \)</span>P(H)<span class="math notranslate nohighlight">\( (\)</span>P(D)$) is the probability of the hypothesis (data).</p>
<p>I always find this very hard to understand.  There are a bunch of variables I don‚Äôt know what they mean.  So, let‚Äôs think about a simple example:</p>
<section id="example-hit-by-a-taxi">
<h2>Example: Hit by a Taxi<a class="headerlink" href="#example-hit-by-a-taxi" title="Permalink to this headline">#</a></h2>
<p>You live in a place where the are 85 percent green taxis and 15 percent blue taxis.  You got hit by a taxi and a witness claims it was blue.  However, it is determined that eye-witness are accurate about 80 percent of the time and mis-identify the color 20 percent of the time.</p>
<p>So the question is ‚Äúwhat is the probability you were hit by a blue cab?‚Äù.  So, our hypothesis (<span class="math notranslate nohighlight">\(H\)</span>) is that we you hit by a blue cab and we want to compute <span class="math notranslate nohighlight">\(P(H|D)\)</span>, given the data (<span class="math notranslate nohighlight">\(D\)</span>) that someone saw a blue cab.  If we didn‚Äôt know the theorem, what would we do?  We would say, the probably a blue cab was involved, knowing nothing else is 15 percent (<span class="math notranslate nohighlight">\(P(H) =0.15)\)</span>) and the probably that someone would see a blue cab if it was a blue cab is 80 percent (<span class="math notranslate nohighlight">\(P(D|H) = 0.80\)</span>).  The answer is not <span class="math notranslate nohighlight">\(0.15 \times 0.80\)</span> because (1) this makes no sense - even when <span class="math notranslate nohighlight">\(P(D|H) =1\)</span> it gives a small probability and (2) the probabilities of the 2 possibilities don‚Äôt add to 1 - <span class="math notranslate nohighlight">\(0.15 \times 0.8 + 0.85 \times 0.2 \neq 1\)</span>.  To normalize our answer correclty, we need to divide by all the different ways we could arrive at the data, namely <span class="math notranslate nohighlight">\(0.15 \times 0.8 + 0.85 \times 0.2\)</span>.  So, our answer is</p>
<div class="math notranslate nohighlight">
\[P(H={\rm blue}|D) = \frac{0.15 \times 0.8}{0.15 \times 0.8 + 0.85 \times 0.2} \sim 0.41\]</div>
<p>Notice that if if the eye witness is perfect (<span class="math notranslate nohighlight">\(P(D|H) = 1\)</span>), our answer is 1, as it should be.</p>
<p>The probability of the data, <span class="math notranslate nohighlight">\(P(D)\)</span>, doesn‚Äôt actually depend on the hypothesis: it is a sum over all possibilities.  Its role in life is just to make the probability normalized to one.  To see this, we note that the only two options are that you got hit by a blue taxi or a green taxi.  If we were to now ask ‚Äúwhat is the probability you were hit by a green taxi?‚Äù, we would have to change <span class="math notranslate nohighlight">\(ùëÉ(ùê∑|ùêª)=0.2\)</span> (there is only a 20% chance that the witness would think it was blue if it was really green) but the probability of the hypothesis itself should <span class="math notranslate nohighlight">\(P(H) = 0.85\)</span> since 85% of taxis are green.  But the probability of the data stays the same, since we already enumated all the possibilities.  This means that
$<span class="math notranslate nohighlight">\(P(H={\rm Green}|D) = \frac{0.2 \times 0.85}{0.15 \times 0.8 + 0.85 \times 0.2} \sim 0.59\)</span><span class="math notranslate nohighlight">\(
Notice that now 
\)</span><span class="math notranslate nohighlight">\(P(H={\rm Green}|D) + P(H={\rm Blue}|D) = 1\)</span><span class="math notranslate nohighlight">\(
This is really what Bayes' theorem is all about: one of the hypotheses must be true, so if \)</span>P(H|D)$ is really a probability, then it must add to up one when we sum over all the possibility.  Bayes‚Äô theorem is just reminding us how to do that.</p>
</section>
<section id="application-coin-flipping">
<h2>Application: coin flipping<a class="headerlink" href="#application-coin-flipping" title="Permalink to this headline">#</a></h2>
<p>Suppose we have a coin that gives us heads with probability <span class="math notranslate nohighlight">\(p\)</span> and tails with probability <span class="math notranslate nohighlight">\(1-p\)</span> where <span class="math notranslate nohighlight">\(p \in [0,1]\)</span> is unknown to us.  Now I flip the coin <span class="math notranslate nohighlight">\(1000\)</span> times and get <span class="math notranslate nohighlight">\(550\)</span> heads and <span class="math notranslate nohighlight">\(450\)</span> tails.  What do you think <span class="math notranslate nohighlight">\(p\)</span> is?</p>
<p>One way to look at it is to simply simulate what happenss with a fair coin as ask it how often you get 550 heads.  Let‚Äôs try 1000 simulations:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">N_sims</span><span class="o">=</span><span class="mi">1000</span>
<span class="n">heads</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">N_sims</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N_sims</span><span class="p">):</span>
    <span class="n">heads</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="n">size</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span><span class="n">ax</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">heads</span><span class="p">,</span><span class="n">bins</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/Topic6a_Bayes_11_0.png" src="_images/Topic6a_Bayes_11_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">heads</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>545.0
</pre></div>
</div>
</div>
</div>
<p>Getting 550 heads is possible but very unlikely when <span class="math notranslate nohighlight">\(p=1/2\)</span> (a fair coin).  Instead, let‚Äôs apply the machinary of Bayes:</p>
<p>Let‚Äôs say we have <span class="math notranslate nohighlight">\(N\)</span> total flips and get <span class="math notranslate nohighlight">\(n\)</span> heads.  The probably of finding <span class="math notranslate nohighlight">\(n\)</span> heads for a given <span class="math notranslate nohighlight">\(p\)</span> gives us the probabability of the data (the likelihood):
$<span class="math notranslate nohighlight">\(P(D | H) = P(n | r) = p^n (1-p)^{N-n} \Big(\frac{N}{n} \Big)\)</span><span class="math notranslate nohighlight">\(
where we have the binomial coefficient \)</span>\Big(\frac{N}{n} \Big)<span class="math notranslate nohighlight">\( which accounts for all the possible ways of getting \)</span>n<span class="math notranslate nohighlight">\( heads (e.g. if you get only \)</span>n=1$, it could have been on the first, second‚Ä¶,last flip of the coin).</p>
<p>We have no idea what the probably of the different models is, so we will assume a flat distribution <span class="math notranslate nohighlight">\(P(p) = \)</span> constant.  Finally, we need to normalize the result by dividing by the integral over <span class="math notranslate nohighlight">\(p\)</span>, such that
$<span class="math notranslate nohighlight">\(P(p| n ) =  p^n (1-p)^{N-n} \Big(\frac{N}{n} \Big) /(\int_0^1 dp p^n (1-p)^{N-n} \Big(\frac{N}{n} \Big))\)</span>$</p>
<p>Let‚Äôs apply this to <span class="math notranslate nohighlight">\(N=1000\)</span> and <span class="math notranslate nohighlight">\(n=550\)</span>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">integrate</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">special</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">integrate</span><span class="o">.</span><span class="n">quad</span><span class="p">(</span><span class="k">lambda</span> <span class="n">p</span><span class="p">:</span><span class="n">p</span><span class="o">**</span><span class="p">(</span><span class="mi">550</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">p</span><span class="p">)</span><span class="o">**</span><span class="p">(</span><span class="mi">450</span><span class="p">)</span><span class="o">*</span><span class="n">special</span><span class="o">.</span><span class="n">binom</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span><span class="mi">500</span><span class="p">),</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(0.14876167743337448, 4.263789920566359e-09)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">p_lin</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1000</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span><span class="n">ax</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">6</span><span class="p">),</span><span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">p_lin</span><span class="p">,</span><span class="n">p_lin</span><span class="o">**</span><span class="p">(</span><span class="mi">550</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">p_lin</span><span class="p">)</span><span class="o">**</span><span class="p">(</span><span class="mi">450</span><span class="p">)</span><span class="o">*</span><span class="n">special</span><span class="o">.</span><span class="n">binom</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span><span class="mi">500</span><span class="p">)</span><span class="o">/</span><span class="mf">0.14876167743337448</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">p_lin</span><span class="p">,</span><span class="n">p_lin</span><span class="o">**</span><span class="p">(</span><span class="mi">550</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">p_lin</span><span class="p">)</span><span class="o">**</span><span class="p">(</span><span class="mi">450</span><span class="p">)</span><span class="o">*</span><span class="n">special</span><span class="o">.</span><span class="n">binom</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span><span class="mi">500</span><span class="p">)</span><span class="o">/</span><span class="mf">0.14876167743337448</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span><span class="mf">0.6</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(0.5, 0.6)
</pre></div>
</div>
<img alt="_images/Topic6a_Bayes_18_1.png" src="_images/Topic6a_Bayes_18_1.png" />
</div>
</div>
<p>Note: the binomial coefficients are totally unnecessary but they keep us from multiplying and dividing by very small numbers:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">integrate</span><span class="o">.</span><span class="n">quad</span><span class="p">(</span><span class="k">lambda</span> <span class="n">p</span><span class="p">:</span><span class="n">p</span><span class="o">**</span><span class="p">(</span><span class="mi">550</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">p</span><span class="p">)</span><span class="o">**</span><span class="p">(</span><span class="mi">450</span><span class="p">),</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(5.505028184578253e-301, 9.11751014007829e-301)
</pre></div>
</div>
</div>
</div>
<p>Now we can still compare to simulations.  Notice that our distribution is peark at 0.55 =550/1000, so we can simulate <span class="math notranslate nohighlight">\(p=0.55\)</span> and compare to our figure</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">N_sims</span><span class="o">=</span><span class="mi">1000</span>
<span class="n">heads_p</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">N_sims</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N_sims</span><span class="p">):</span>
    <span class="n">heads_p</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">=</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mf">0.55</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">/</span><span class="mf">1000.</span>   
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span><span class="n">ax</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">heads_p</span><span class="p">,</span><span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">p_lin</span><span class="p">,</span><span class="n">p_lin</span><span class="o">**</span><span class="p">(</span><span class="mi">550</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">p_lin</span><span class="p">)</span><span class="o">**</span><span class="p">(</span><span class="mi">450</span><span class="p">)</span><span class="o">*</span><span class="n">special</span><span class="o">.</span><span class="n">binom</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span><span class="mi">500</span><span class="p">)</span><span class="o">/</span><span class="mf">0.14876167743337448</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span><span class="mf">0.6</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(0.5, 0.6)
</pre></div>
</div>
<img alt="_images/Topic6a_Bayes_23_1.png" src="_images/Topic6a_Bayes_23_1.png" />
</div>
</div>
</section>
<section id="gaussian-noise">
<h2>Gaussian Noise<a class="headerlink" href="#gaussian-noise" title="Permalink to this headline">#</a></h2>
<p>Now let us return to our previous discussion of data where we had a deterministic model for the signal and a random source of noise
$<span class="math notranslate nohighlight">\( data(t)=S(t) + noise(t)\)</span><span class="math notranslate nohighlight">\( 
The noise is drawn from a Gaussian distribution with a standard deviation \)</span>\sigma$.</p>
<p>It is definitely easier to measure <span class="math notranslate nohighlight">\(S(t)\)</span> if we know what <span class="math notranslate nohighlight">\(\sigma\)</span> is ahead of time.  But how would we know this?  In many cases, we can simply make a measurement when we know there is no signal.  E.g. if you cover up a telescope, then the pictures you take are just the noise of your camera.  By doing this, we get <span class="math notranslate nohighlight">\(N\)</span> measurements drawn from a Gaussian distribution but we don‚Äôt know <span class="math notranslate nohighlight">\(\sigma\)</span>.  Now we can use our machinary of Bayesian inference to figure it out.  For each data point, <span class="math notranslate nohighlight">\(n_i\)</span>, the probability of the data, given a <span class="math notranslate nohighlight">\(\sigma\)</span> is
$<span class="math notranslate nohighlight">\(P(n_i) =\frac{\Delta n}{\sqrt{2\pi}\sigma} e^{-n_i^2/(2\sigma^2)}\)</span><span class="math notranslate nohighlight">\( 
where \)</span>\Delta n<span class="math notranslate nohighlight">\( is accuracy with which I measure the noise, i.e. it is the size of the bins in which we group \)</span>n_i$ since we are not measuring to infinite accuracy.</p>
<p>Let‚Äôs assume we know thing about <span class="math notranslate nohighlight">\(\sigma\)</span> so that <span class="math notranslate nohighlight">\(P(\sigma) =\)</span> constant, since <span class="math notranslate nohighlight">\(P(D)\)</span> is also just some constant, we can worry about normalization our result later.  Putting this together, we have
$<span class="math notranslate nohighlight">\( P(\sigma | n_i) = \prod_i P(n_i) = \frac{1}{(2\pi)^{N/2} \sigma^N} e^{-(\sum_i n_i^2)/(2\sigma^2)}\)</span>$</p>
<p>We learn wwo things: (1) we recall that <span class="math notranslate nohighlight">\(\sum_i n_i^2 \approx N \bar \sigma^2\)</span> where <span class="math notranslate nohighlight">\(\bar \sigma\)</span> is the true variance.  We can make a figure of this function:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">integrate</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">s</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.6</span><span class="p">,</span><span class="mf">1.4</span><span class="p">,</span><span class="mi">100</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">chiout</span><span class="p">(</span><span class="n">s</span><span class="p">,</span><span class="n">N</span><span class="p">,</span><span class="n">s0</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">const</span><span class="o">=</span><span class="n">integrate</span><span class="o">.</span><span class="n">quad</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">N</span><span class="o">*</span><span class="n">s0</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span><span class="o">/</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">*</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">**</span><span class="p">(</span><span class="n">N</span><span class="p">)),</span><span class="mf">0.2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">limit</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">N</span><span class="o">*</span><span class="n">s0</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">s</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span><span class="o">/</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">*</span><span class="n">s</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">**</span><span class="p">(</span><span class="n">N</span><span class="p">))</span><span class="o">/</span><span class="n">const</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">s</span><span class="p">,</span><span class="n">chiout</span><span class="p">(</span><span class="n">s</span><span class="p">,</span><span class="mi">20</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">s</span><span class="p">,</span><span class="n">chiout</span><span class="p">(</span><span class="n">s</span><span class="p">,</span><span class="mi">80</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">s</span><span class="p">,</span><span class="n">chiout</span><span class="p">(</span><span class="n">s</span><span class="p">,</span><span class="mi">320</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&lt;matplotlib.lines.Line2D at 0x12151f940&gt;]
</pre></div>
</div>
<img alt="_images/Topic6a_Bayes_28_1.png" src="_images/Topic6a_Bayes_28_1.png" />
</div>
</div>
<p>We see that this follows a familiar pattern: when we increase the amount data by a factor of 4, the width of these curves decreases by a factor of two.  Said differently our error scales as <span class="math notranslate nohighlight">\(1/\sqrt{N}\)</span></p>
<p>(2) we can apply this to data for any <span class="math notranslate nohighlight">\(n_i\)</span> and find the maximum <span class="math notranslate nohighlight">\(\sigma\)</span>. The maximum likelihood will will not necessarily reproduce the one we used to represent the data, but the likelihood should include a reasonably large probability of the true value.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ni</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">chi_data</span><span class="p">(</span><span class="n">s</span><span class="p">,</span><span class="n">n_in</span><span class="p">):</span>
    <span class="n">noise2</span><span class="o">=</span><span class="p">(</span><span class="n">n_in</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="n">N</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">n_in</span><span class="p">)</span>
    <span class="n">const</span><span class="o">=</span><span class="n">integrate</span><span class="o">.</span><span class="n">quad</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">noise2</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span><span class="o">/</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">*</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">**</span><span class="p">(</span><span class="n">N</span><span class="p">)),</span><span class="mf">0.2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">limit</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">const</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">noise2</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">s</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span><span class="o">/</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">*</span><span class="n">s</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">**</span><span class="p">(</span><span class="n">N</span><span class="p">))</span><span class="o">/</span><span class="n">const</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
    <span class="n">ni</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">50</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">s</span><span class="p">,</span><span class="n">chi_data</span><span class="p">(</span><span class="n">s</span><span class="p">,</span><span class="n">ni</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(4.372129572567773e-32, 2.0662824425442126e-33)
(1.8240521694799357e-31, 3.0056520286038797e-34)
(6.250989872809787e-32, 2.3781059745672675e-33)
(2.3631955935466617e-33, 3.654808244703056e-36)
(1.2365112313922088e-30, 2.979037196263022e-31)
(1.3125919282949607e-27, 9.950612044298351e-28)
(1.912201515856392e-29, 2.1369011910323926e-32)
(2.3060441467182898e-29, 5.507964964444194e-31)
(7.168012629118421e-29, 4.51057372062073e-29)
(1.4298236207569674e-27, 9.526810708751135e-28)
</pre></div>
</div>
<img alt="_images/Topic6a_Bayes_33_1.png" src="_images/Topic6a_Bayes_33_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
    <span class="n">ni</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">300</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">s</span><span class="p">,</span><span class="n">chi_data</span><span class="p">(</span><span class="n">s</span><span class="p">,</span><span class="n">ni</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(2.1907643168050416e-182, 3.4033535810970035e-182)
(3.5656424577469174e-186, 6.896545388481329e-187)
(8.627487939367348e-192, 1.2682130672888978e-191)
(5.815698140530597e-184, 8.850725305998306e-184)
(1.1751302652090763e-180, 1.8455065026865918e-180)
(6.660622683601882e-185, 1.0293582155762576e-184)
(9.228252870291996e-185, 1.4224449569031609e-184)
(5.301077057635474e-189, 8.236403373858258e-189)
(1.0346828820457025e-181, 1.6168927333812585e-181)
(3.861957040420618e-188, 6.051188545138598e-188)
</pre></div>
</div>
<img alt="_images/Topic6a_Bayes_34_1.png" src="_images/Topic6a_Bayes_34_1.png" />
</div>
</div>
<p>Of course, we know the maximum of this curve will lie at <span class="math notranslate nohighlight">\(\sigma = \sqrt{\sum n_i^2/N}\)</span>, so we can also just make a histogram of the maximum likelihood points as</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Nsims</span><span class="o">=</span><span class="mi">1000</span>
<span class="n">Ndata</span><span class="o">=</span><span class="mi">100</span>
<span class="n">max_list</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">Nsims</span><span class="p">)</span>
<span class="n">max_list_h</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">Nsims</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">Nsims</span><span class="p">):</span>
    <span class="n">ni</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">Ndata</span><span class="p">)</span>
    <span class="n">max_list</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">((</span><span class="n">ni</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">/</span><span class="n">Ndata</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span><span class="n">ax</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">max_list</span><span class="p">,</span><span class="n">bins</span><span class="o">=</span><span class="mi">40</span><span class="p">)</span>
<span class="n">Ndata</span><span class="o">=</span><span class="mi">400</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">Nsims</span><span class="p">):</span>
    <span class="n">ni</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">Ndata</span><span class="p">)</span>
    <span class="n">max_list_h</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">((</span><span class="n">ni</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">/</span><span class="n">Ndata</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">max_list_h</span><span class="p">,</span><span class="n">bins</span><span class="o">=</span><span class="mi">40</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/Topic6a_Bayes_36_0.png" src="_images/Topic6a_Bayes_36_0.png" />
</div>
</div>
<p>We again see that the width of these histograms scales as <span class="math notranslate nohighlight">\(1/\sqrt{N}\)</span>.</p>
<section id="bayesian-inference-for-the-signal">
<h3>Bayesian Inference for the Signal<a class="headerlink" href="#bayesian-inference-for-the-signal" title="Permalink to this headline">#</a></h3>
<p>Taking enough data with no signal, we can determine <span class="math notranslate nohighlight">\(\sigma\)</span> to good enough accuracy that we will assume it is known.  This isn‚Äôt always true, but it simplifies how we think about measuring the signal.  We return again to our assumption, but now let‚Äôs make it clear that our hypothesis is only about the signal:
$<span class="math notranslate nohighlight">\( data(t|H)=S(t|H) + noise(t)\)</span><span class="math notranslate nohighlight">\( 
However, the only thing that is random is the noise, so the probability of the data is simply:
\)</span><span class="math notranslate nohighlight">\(P(D|H) =\frac{1}{(2\pi)^{N/2} \sigma^N} e^{-(\sum_i (data(t_i) - S(t_i))^2/(2\sigma^2)}\)</span><span class="math notranslate nohighlight">\(
This is literally just the same equation we had before since \)</span>data_i -S_i =n_i<span class="math notranslate nohighlight">\(.  However, now our posterior is for the parameters of our model, rather than \)</span>\sigma$.</p>
<p>Let‚Äôs see how this works for a line with noise:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">trange</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">1000</span><span class="p">)</span>
<span class="n">data_t</span><span class="o">=</span><span class="mf">0.07</span><span class="o">*</span><span class="n">trange</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">Pos_line</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">,</span><span class="n">t</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">noise2</span><span class="o">=</span><span class="p">((</span><span class="n">data</span><span class="o">-</span><span class="n">a</span><span class="o">*</span><span class="n">t</span><span class="o">-</span><span class="n">b</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">noise2</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">s</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">a_r</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mf">0.12</span><span class="p">,</span><span class="mi">100</span><span class="p">)</span>
<span class="n">Pos_r</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">Pos_r</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">=</span><span class="n">Pos_line</span><span class="p">(</span><span class="n">data_t</span><span class="p">,</span><span class="n">a_r</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="mi">0</span><span class="p">,</span><span class="n">trange</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">a_r</span><span class="p">,</span><span class="n">Pos_r</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/Topic6a_Bayes_43_0.png" src="_images/Topic6a_Bayes_43_0.png" />
</div>
</div>
<p>We notice the very small size of the posterior here, because I didn‚Äôt bother to normal by dividing by <span class="math notranslate nohighlight">\(P(D)\)</span>. In practice, we we need to know about the postior is just the maximum likelihood point and <span class="math notranslate nohighlight">\(1\sigma\)</span>, <span class="math notranslate nohighlight">\(2\sigma\)</span>, <span class="math notranslate nohighlight">\(3\sigma\)</span> lines. However for this we don‚Äôt actually need to work with the full posterior.  Instead we can take the log:
$<span class="math notranslate nohighlight">\(-2\log P(H,D) = \sum_i (data(t_i) - S(t_i))^2/(\sigma^2) +{\rm constant} \)</span><span class="math notranslate nohighlight">\(
We see that minimizing \)</span>-\log P(H,D)<span class="math notranslate nohighlight">\( is exactly the same quantity we minimized in finding our best fit curves.  Now suppose that in the vacinity of the maximum likelihood point for a parameter of our model, \)</span>a<span class="math notranslate nohighlight">\( we have
\)</span><span class="math notranslate nohighlight">\( -\log P(H,D) \approx -\frac{(a-a_{\rm min})^2}{2 \sigma_a^2}\)</span><span class="math notranslate nohighlight">\(
Then when \)</span>a = a_{\rm min} + n \sigma_a<span class="math notranslate nohighlight">\( we have \)</span>-2\log P(H,D) = -2\log P(H,D)|<em>{a</em>{\rm min}}+ n^2$</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">chi_line</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">,</span><span class="n">t</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">noise2</span><span class="o">=</span><span class="p">((</span><span class="n">data</span><span class="o">-</span><span class="n">a</span><span class="o">*</span><span class="n">t</span><span class="o">-</span><span class="n">b</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">noise2</span><span class="o">/</span><span class="p">(</span><span class="n">s</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">chi_r</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">chi_r</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">=</span><span class="n">chi_line</span><span class="p">(</span><span class="n">data_t</span><span class="p">,</span><span class="n">a_r</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="mi">0</span><span class="p">,</span><span class="n">trange</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">a_r</span><span class="p">,</span><span class="n">chi_r</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/Topic6a_Bayes_46_0.png" src="_images/Topic6a_Bayes_46_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="kn">import</span> <span class="n">minimize</span>
<span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="kn">import</span> <span class="n">newton</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">a_min_loc</span><span class="o">=</span><span class="n">minimize</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">chi_line</span><span class="p">(</span><span class="n">data_t</span><span class="p">,</span><span class="n">x</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="n">trange</span><span class="p">),</span><span class="mf">0.070</span><span class="p">)[</span><span class="s1">&#39;x&#39;</span><span class="p">]</span>
<span class="n">minimize</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">chi_line</span><span class="p">(</span><span class="n">data_t</span><span class="p">,</span><span class="n">x</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="n">trange</span><span class="p">),</span><span class="mf">0.070</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>      fun: 1095.9815489828575
 hess_inv: array([[1.49924966e-05]])
      jac: array([3.05175781e-05])
  message: &#39;Desired error not necessarily achieved due to precision loss.&#39;
     nfev: 76
      nit: 1
     njev: 32
   status: 2
  success: False
        x: array([0.06340272])
</pre></div>
</div>
</div>
</div>
<p>Having found the location of the minimum, we now proceed to find the value of the minimum and the location of the <span class="math notranslate nohighlight">\(1\sigma\)</span> and <span class="math notranslate nohighlight">\(2\sigma\)</span> contours:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">chi_min</span><span class="o">=</span><span class="n">chi_line</span><span class="p">(</span><span class="n">data_t</span><span class="p">,</span><span class="n">a_min_loc</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="n">trange</span><span class="p">)</span>
<span class="n">Pos_max</span><span class="o">=</span><span class="n">Pos_line</span><span class="p">(</span><span class="n">data_t</span><span class="p">,</span><span class="n">a_min_loc</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="n">trange</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">chi_min</span><span class="p">,</span><span class="n">Pos_max</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1095.9815489828575 1.0247796779601787e-238
</pre></div>
</div>
</div>
</div>
<p>The <span class="math notranslate nohighlight">\(1\sigma\)</span> lines are the minimum <span class="math notranslate nohighlight">\(\chi^2 +1\)</span></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">s1L</span><span class="o">=</span><span class="n">newton</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">chi_line</span><span class="p">(</span><span class="n">data_t</span><span class="p">,</span><span class="n">x</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="n">trange</span><span class="p">)</span><span class="o">-</span><span class="n">chi_min</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mf">0.065</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">s1L</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.06887857997310061
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">s1R</span><span class="o">=</span><span class="n">newton</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">chi_line</span><span class="p">(</span><span class="n">data_t</span><span class="p">,</span><span class="n">x</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="n">trange</span><span class="p">)</span><span class="o">-</span><span class="n">chi_min</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mf">0.08</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">s1R</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.0688785799740147
</pre></div>
</div>
</div>
</div>
<p>The <span class="math notranslate nohighlight">\(2\sigma\)</span> lines are the minimum <span class="math notranslate nohighlight">\(\chi^2 +2\)</span></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">s2L</span><span class="o">=</span><span class="n">newton</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">chi_line</span><span class="p">(</span><span class="n">data_t</span><span class="p">,</span><span class="n">x</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="n">trange</span><span class="p">)</span><span class="o">-</span><span class="n">chi_min</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span><span class="mf">0.065</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">s2L</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.0743544353853341
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">s2R</span><span class="o">=</span><span class="n">newton</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">chi_line</span><span class="p">(</span><span class="n">data_t</span><span class="p">,</span><span class="n">x</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="n">trange</span><span class="p">)</span><span class="o">-</span><span class="n">chi_min</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span><span class="mf">0.08</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">s2R</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.07435443538538289
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">chi_min</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1095.9815489828575
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span><span class="n">ax</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">6</span><span class="p">),</span><span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">a_r</span><span class="p">,</span><span class="n">chi_r</span><span class="p">,</span><span class="n">lw</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">s1L</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">),[</span><span class="n">chi_min</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="n">chi_min</span><span class="o">+</span><span class="mi">10</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;darkorange&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">s1R</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">),[</span><span class="n">chi_min</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="n">chi_min</span><span class="o">+</span><span class="mi">10</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;darkorange&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">s2L</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">),[</span><span class="n">chi_min</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="n">chi_min</span><span class="o">+</span><span class="mi">10</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;darkblue&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">s2R</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">),[</span><span class="n">chi_min</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="n">chi_min</span><span class="o">+</span><span class="mi">10</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;darkblue&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mf">0.055</span><span class="p">,</span><span class="mf">0.09</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="n">chi_min</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="n">chi_min</span><span class="o">+</span><span class="mi">10</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">a_r</span><span class="p">,</span><span class="n">Pos_r</span><span class="o">/</span><span class="n">Pos_max</span><span class="p">,</span><span class="n">lw</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">s1L</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">),[</span><span class="mi">0</span><span class="p">,</span><span class="mf">1.1</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;darkorange&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">s1R</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">),[</span><span class="mi">0</span><span class="p">,</span><span class="mf">1.1</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;darkorange&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">s2L</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">),[</span><span class="mi">0</span><span class="p">,</span><span class="mf">1.1</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;darkblue&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">s2R</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">),[</span><span class="mi">0</span><span class="p">,</span><span class="mf">1.1</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;darkblue&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mf">0.055</span><span class="p">,</span><span class="mf">0.09</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mf">1.1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/Topic6a_Bayes_58_0.png" src="_images/Topic6a_Bayes_58_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">a_min_loc</span><span class="o">-</span><span class="n">s1L</span><span class="p">,</span><span class="n">s1R</span><span class="o">-</span><span class="n">a_min_loc</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">a_min_loc</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[-0.00547586] [0.00547586]
[0.06340272]
</pre></div>
</div>
</div>
</div>
<p>At <span class="math notranslate nohighlight">\(1\sigma\)</span>, we have determined that <span class="math notranslate nohighlight">\(a = a_{\rm min} \pm 0.0055\)</span></p>
<p>Now, our line is really a two dimensional space, not a one dimensional space. In this case we have two options: (1) we want to know the multi-dimensional behavior (make a contour plot) or (2) we average over a parameter we don‚Äôt care about (marginalize).</p>
<p>First, let us repeat what we did above but now using the model <span class="math notranslate nohighlight">\(S(t|a,b)= a t+b\)</span>.  First we find the minimum</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">minimize</span><span class="p">(</span><span class="k">lambda</span> <span class="n">X</span><span class="p">:</span><span class="n">chi_line</span><span class="p">(</span><span class="n">data_t</span><span class="p">,</span><span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">X</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">trange</span><span class="p">),[</span><span class="mf">0.07</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span><span class="n">method</span><span class="o">=</span><span class="s1">&#39;Nelder-Mead&#39;</span><span class="p">,</span><span class="n">tol</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> final_simplex: (array([[0.05030447, 0.08736517],
       [0.05030455, 0.0873653 ],
       [0.05030469, 0.08736423]]), array([1094.07051715, 1094.07051715, 1094.07051715]))
           fun: 1094.0705171525187
       message: &#39;Optimization terminated successfully.&#39;
          nfev: 108
           nit: 57
        status: 0
       success: True
             x: array([0.05030447, 0.08736517])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">line_sol</span><span class="o">=</span><span class="n">minimize</span><span class="p">(</span><span class="k">lambda</span> <span class="n">X</span><span class="p">:</span><span class="n">chi_line</span><span class="p">(</span><span class="n">data_t</span><span class="p">,</span><span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">X</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">trange</span><span class="p">),[</span><span class="mf">0.07</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span><span class="n">method</span><span class="o">=</span><span class="s1">&#39;Nelder-Mead&#39;</span><span class="p">,</span><span class="n">tol</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">)[</span><span class="s1">&#39;x&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>It might seem a bit surprising that when we fit the line, the best fit value of <span class="math notranslate nohighlight">\(a\)</span> is quite far from our best fit result.  Concretely, when we set <span class="math notranslate nohighlight">\(b=0\)</span>, we got <span class="math notranslate nohighlight">\(a\sim 0.07 \pm 0.055\)</span> and now our best fit <span class="math notranslate nohighlight">\(a\)</span> looks like it is more than 2<span class="math notranslate nohighlight">\(\sigma\)</span> off.  We can check that the line is a good fit to the data</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">trange</span><span class="p">,</span><span class="n">data_t</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">trange</span><span class="p">,</span><span class="n">line_sol</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">trange</span><span class="o">+</span><span class="n">line_sol</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">lw</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;darkorange&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">trange</span><span class="p">,</span><span class="mf">0.07</span><span class="o">*</span><span class="n">trange</span><span class="p">,</span><span class="n">lw</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;darkred&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/Topic6a_Bayes_66_0.png" src="_images/Topic6a_Bayes_66_0.png" />
</div>
</div>
<p>Now let‚Äôs understand what is going on by making a figure of the 2D posterior.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">chi_min_line</span><span class="o">=</span><span class="n">chi_line</span><span class="p">(</span><span class="n">data_t</span><span class="p">,</span><span class="n">line_sol</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">line_sol</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">trange</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">chi_min_line</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1094.0705171525187
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">b_r</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="mf">0.5</span><span class="p">,</span><span class="mi">100</span><span class="p">)</span>
<span class="n">A</span><span class="p">,</span><span class="n">B</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">a_r</span><span class="p">,</span><span class="n">b_r</span><span class="p">)</span>
<span class="n">logP</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
        <span class="n">logP</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span><span class="o">=</span><span class="n">chi_line</span><span class="p">(</span><span class="n">data_t</span><span class="p">,</span><span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">],</span><span class="n">B</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">],</span><span class="n">trange</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>In order to choose contours, we need to know the values of <span class="math notranslate nohighlight">\(\chi^2\)</span> that correspond the 1<span class="math notranslate nohighlight">\(\sigma\)</span> (~68%) and <span class="math notranslate nohighlight">\(2\sigma\)</span>(~95%) confidence regions (i.e. you have the same probability of finding the true mode there as if it was a <span class="math notranslate nohighlight">\(1\sigma\)</span> or <span class="math notranslate nohighlight">\(2\sigma\)</span> line for a Gaussian.  For a 2 dimensional space, the answer is 2.3 and 6.18 so we make the contours as:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span><span class="n">ax</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">contour</span><span class="p">(</span><span class="n">A</span><span class="p">,</span><span class="n">B</span><span class="p">,</span><span class="n">logP</span><span class="p">,</span><span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;RdBu&#39;</span><span class="p">,</span><span class="n">levels</span><span class="o">=</span><span class="p">[</span><span class="n">chi_min_line</span><span class="o">+</span><span class="mf">2.30</span><span class="p">,</span><span class="n">chi_min_line</span><span class="o">+</span><span class="mf">6.18</span><span class="p">])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="mf">0.07</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="n">marker</span><span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;darkred&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">s1L</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">b_r</span><span class="p">)),</span><span class="n">b_r</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;darkorange&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">s1R</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">b_r</span><span class="p">)),</span><span class="n">b_r</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;darkorange&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">s2L</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">b_r</span><span class="p">)),</span><span class="n">b_r</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;darkblue&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">s2R</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">b_r</span><span class="p">)),</span><span class="n">b_r</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;darkblue&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/Topic6a_Bayes_71_0.png" src="_images/Topic6a_Bayes_71_0.png" />
</div>
</div>
<p>This figure reveals that it is pretty hard to tell apart <span class="math notranslate nohighlight">\(a\)</span> and <span class="math notranslate nohighlight">\(b\)</span>.  When we include the possibility of <span class="math notranslate nohighlight">\(b\neq 0\)</span>, we see that the allowed values of <span class="math notranslate nohighlight">\(a\)</span> cover a much larger region compared to the lines that show the 1<span class="math notranslate nohighlight">\(\sigma\)</span> and 2<span class="math notranslate nohighlight">\(\sigma\)</span> lines we found when <span class="math notranslate nohighlight">\(b=0\)</span>.</p>
<p>We can also look at this in terms of the posterior for <span class="math notranslate nohighlight">\(a\)</span> ignoring <span class="math notranslate nohighlight">\(b\)</span>.  Rather than a conditional probability for the pair <span class="math notranslate nohighlight">\((a,b)\)</span> we just want to know the probability of <span class="math notranslate nohighlight">\(a\)</span> including all possible <span class="math notranslate nohighlight">\(b\)</span> values.</p>
<p>We can think of this like we are flipping a pair of coins and we want to count how often they match.  We have to add up all the cases where you get two heads or two tails, even though we know they are different.  We are doing the same here, we are going to add up all pairs of <span class="math notranslate nohighlight">\((a,b)\)</span> that have the same value of <span class="math notranslate nohighlight">\(a\)</span>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">chi_marg</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="n">a</span><span class="p">,</span><span class="n">t</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">Mar_pos</span><span class="o">=</span><span class="n">integrate</span><span class="o">.</span><span class="n">quad</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">Pos_line</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="n">a</span><span class="p">,</span><span class="n">x</span><span class="p">,</span><span class="n">t</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">return</span> <span class="o">-</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">Mar_pos</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">chi_marg</span><span class="p">(</span><span class="n">data_t</span><span class="p">,</span><span class="mf">0.07</span><span class="p">,</span><span class="n">trange</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1102.3795001843712
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">chi_mar_out</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">a_r</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">a_r</span><span class="p">)):</span>
    <span class="n">chi_mar_out</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">=</span><span class="n">chi_marg</span><span class="p">(</span><span class="n">data_t</span><span class="p">,</span><span class="n">a_r</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">trange</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">a_r</span><span class="p">,</span><span class="n">chi_mar_out</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&lt;matplotlib.lines.Line2D at 0x1215b87c0&gt;]
</pre></div>
</div>
<img alt="_images/Topic6a_Bayes_77_1.png" src="_images/Topic6a_Bayes_77_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">a_min_marg</span><span class="o">=</span><span class="n">minimize</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">chi_marg</span><span class="p">(</span><span class="n">data_t</span><span class="p">,</span><span class="n">x</span><span class="p">,</span><span class="n">trange</span><span class="p">),</span><span class="mf">0.080</span><span class="p">,</span><span class="n">method</span><span class="o">=</span><span class="s1">&#39;Nelder-Mead&#39;</span><span class="p">,</span><span class="n">tol</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">)[</span><span class="s1">&#39;x&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">chi_min_marg</span><span class="o">=</span><span class="n">chi_marg</span><span class="p">(</span><span class="n">data_t</span><span class="p">,</span><span class="n">a_min_marg</span><span class="p">,</span><span class="n">trange</span><span class="p">)</span>    
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">s1L_marg</span><span class="o">=</span><span class="n">newton</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">chi_marg</span><span class="p">(</span><span class="n">data_t</span><span class="p">,</span><span class="n">x</span><span class="p">,</span><span class="n">trange</span><span class="p">)</span><span class="o">-</span><span class="n">chi_min_marg</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mf">0.07</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">s1L_marg</span><span class="p">)</span>
<span class="n">s1R_marg</span><span class="o">=</span><span class="n">newton</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">chi_marg</span><span class="p">(</span><span class="n">data_t</span><span class="p">,</span><span class="n">x</span><span class="p">,</span><span class="n">trange</span><span class="p">)</span><span class="o">-</span><span class="n">chi_min_marg</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mf">0.09</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">s1R_marg</span><span class="p">)</span>
<span class="n">s2L_marg</span><span class="o">=</span><span class="n">newton</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">chi_marg</span><span class="p">(</span><span class="n">data_t</span><span class="p">,</span><span class="n">x</span><span class="p">,</span><span class="n">trange</span><span class="p">)</span><span class="o">-</span><span class="n">chi_min_marg</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span><span class="mf">0.07</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">s2L_marg</span><span class="p">)</span>
<span class="n">s2R_marg</span><span class="o">=</span><span class="n">newton</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">chi_marg</span><span class="p">(</span><span class="n">data_t</span><span class="p">,</span><span class="n">x</span><span class="p">,</span><span class="n">trange</span><span class="p">)</span><span class="o">-</span><span class="n">chi_min_marg</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span><span class="mf">0.09</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">s2R_marg</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.06124070435465533
0.06124070435456302
0.07218762645743809
0.07218762645767614
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span><span class="n">ax</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">a_r</span><span class="p">,</span><span class="n">chi_mar_out</span><span class="p">,</span><span class="n">lw</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">a_r</span><span class="p">,</span><span class="n">chi_r</span><span class="p">,</span><span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;indigo&#39;</span><span class="p">,</span><span class="n">ls</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">s1L_marg</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">),[</span><span class="n">chi_min_marg</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span><span class="n">chi_min_marg</span><span class="o">+</span><span class="mi">10</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;darkorange&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">s1R_marg</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">),[</span><span class="n">chi_min_marg</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span><span class="n">chi_min_marg</span><span class="o">+</span><span class="mi">10</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;darkorange&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">s2L_marg</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">),[</span><span class="n">chi_min_marg</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span><span class="n">chi_min_marg</span><span class="o">+</span><span class="mi">10</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;darkblue&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">s2R_marg</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">),[</span><span class="n">chi_min_marg</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span><span class="n">chi_min_marg</span><span class="o">+</span><span class="mi">10</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;darkblue&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mf">0.055</span><span class="p">,</span><span class="mf">0.12</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="n">chi_min_marg</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span><span class="n">chi_min_marg</span><span class="o">+</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(1095.1389106871386, 1109.1389106871386)
</pre></div>
</div>
<img alt="_images/Topic6a_Bayes_81_1.png" src="_images/Topic6a_Bayes_81_1.png" />
</div>
</div>
</section>
</section>
<section id="generalizations">
<h2>Generalizations<a class="headerlink" href="#generalizations" title="Permalink to this headline">#</a></h2>
<p><strong>Priors</strong> Notice that the marginalized likelihood is much wider than the one where <span class="math notranslate nohighlight">\(b=0\)</span>.  This makes sense, because forcing <span class="math notranslate nohighlight">\(b=0\)</span> is some kind of extra knowledge we used.</p>
<p>We can make sense of this using the idea of a prior, <span class="math notranslate nohighlight">\(P(H)\)</span>.  Specifically, the two extremes we have considered are just limits of the prior
$<span class="math notranslate nohighlight">\(P(b) =\frac{1}{\sqrt{2\pi \sigma_b^2}} e^{-b^2/(2 \sigma_b^2)} \)</span><span class="math notranslate nohighlight">\(
When \)</span>\sigma_b \to 0<span class="math notranslate nohighlight">\(, we recover the case where \)</span>b=0<span class="math notranslate nohighlight">\( and when \)</span>\sigma_b \to \infty<span class="math notranslate nohighlight">\( we recover a flat prior on \)</span>b$.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">chi_marg_prior</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="n">a</span><span class="p">,</span><span class="n">t</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">b</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="n">sb</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">Mar_pos</span><span class="o">=</span><span class="n">integrate</span><span class="o">.</span><span class="n">quad</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">Pos_line</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="n">a</span><span class="p">,</span><span class="n">x</span><span class="p">,</span><span class="n">t</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="n">b</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">sb</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span><span class="o">/</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">*</span><span class="n">sb</span><span class="o">**</span><span class="mi">2</span><span class="p">)),</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">epsabs</span><span class="o">=</span><span class="mf">1.49e-16</span><span class="p">,</span> <span class="n">epsrel</span><span class="o">=</span><span class="mf">1.49e-16</span><span class="p">,</span> <span class="n">limit</span><span class="o">=</span><span class="mi">10000</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">return</span> <span class="o">-</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">Mar_pos</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">chi_prior</span><span class="o">=</span><span class="p">{}</span>
<span class="n">sig_b</span><span class="o">=</span><span class="p">[</span><span class="mf">0.3</span><span class="p">,</span><span class="mf">0.1</span><span class="p">,</span><span class="mf">0.03</span><span class="p">,</span><span class="mf">0.01</span><span class="p">]</span>
<span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">sig_b</span><span class="p">:</span>
    <span class="n">chi_prior</span><span class="p">[</span><span class="n">s</span><span class="p">]</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">a_r</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">a_r</span><span class="p">)):</span>
    <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">sig_b</span><span class="p">:</span>
        <span class="n">chi_prior</span><span class="p">[</span><span class="n">s</span><span class="p">][</span><span class="n">i</span><span class="p">]</span><span class="o">=</span><span class="n">chi_marg_prior</span><span class="p">(</span><span class="n">data_t</span><span class="p">,</span><span class="n">a_r</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">trange</span><span class="p">,</span><span class="n">sb</span><span class="o">=</span><span class="n">s</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span><span class="n">ax</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
<span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">sig_b</span><span class="p">:</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">a_r</span><span class="p">,</span><span class="n">chi_prior</span><span class="p">[</span><span class="n">s</span><span class="p">],</span><span class="n">label</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span><span class="n">s</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">a_r</span><span class="p">,</span><span class="n">chi_r</span><span class="p">,</span><span class="n">ls</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/Topic6a_Bayes_86_0.png" src="_images/Topic6a_Bayes_86_0.png" />
</div>
</div>
<p>We see in this way what priors are doing for us: they are making it clear how to go between modes with more parameters and less parameters.  Reducing the number of parameters is an extreme version of adding information about parameters in the form of a prior.</p>
<p>However, as we will see in the next topic, there is a reason we don‚Äôt just add models with lots of parameters and lots of priors when we don‚Äôt need to: this integral to marginalize of <span class="math notranslate nohighlight">\(b\)</span> becomes very challenging very quickly.</p>
<p><strong>Non-uniform Errors</strong> So far we have been treating the error (std deviation of the noise) <span class="math notranslate nohighlight">\(\sigma\)</span> as constant. When doing this, we saw that finding the maximum value of the posterior was the same the least squares fit that is typical of linear regression algorithms.</p>
<p>However, it is not true that the error in most data is uniform. For example, we might want to combine data taken at different times or with different detectors where the noise.  However, in many of these cases, we still understand the noise well enough to treak <span class="math notranslate nohighlight">\(\sigma\)</span> as a known quantity.</p>
<p>We can easily adjust our model to include this option</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">chi_line_s</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">,</span><span class="n">t</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">noise2</span><span class="o">=</span><span class="p">((</span><span class="n">data</span><span class="o">-</span><span class="n">a</span><span class="o">*</span><span class="n">t</span><span class="o">-</span><span class="n">b</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="p">(</span><span class="n">s</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">noise2</span>
</pre></div>
</div>
</div>
</div>
<p>This still has <span class="math notranslate nohighlight">\(s=1\)</span> as a default, but let‚Äôs put in <span class="math notranslate nohighlight">\(s\)</span> is a decreasing function of time for both the data and our chi</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data_s</span><span class="o">=</span><span class="mf">0.07</span><span class="o">*</span><span class="n">trange</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="mf">0.1</span><span class="o">+</span><span class="p">(</span><span class="n">trange</span><span class="o">-</span><span class="mi">5</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="mi">25</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">s_r</span><span class="o">=</span><span class="p">(</span><span class="mf">0.1</span><span class="o">+</span><span class="p">(</span><span class="n">trange</span><span class="o">-</span><span class="mi">5</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="mi">25</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">chi_line_s</span><span class="p">(</span><span class="n">data_s</span><span class="p">,</span><span class="mf">0.07</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="n">trange</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="n">s_r</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>986.8217987942159
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">a_min_loc_s</span><span class="o">=</span><span class="n">minimize</span><span class="p">(</span><span class="k">lambda</span> <span class="n">X</span><span class="p">:</span><span class="n">chi_line_s</span><span class="p">(</span><span class="n">data_s</span><span class="p">,</span><span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">X</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">trange</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="n">s_r</span><span class="p">),[</span><span class="mf">0.070</span><span class="p">,</span><span class="mi">0</span><span class="p">])[</span><span class="s1">&#39;x&#39;</span><span class="p">]</span>
<span class="n">a_min_loc_wrong</span><span class="o">=</span><span class="n">minimize</span><span class="p">(</span><span class="k">lambda</span> <span class="n">X</span><span class="p">:</span><span class="n">chi_line</span><span class="p">(</span><span class="n">data_s</span><span class="p">,</span><span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">X</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">trange</span><span class="p">),[</span><span class="mf">0.070</span><span class="p">,</span><span class="mi">0</span><span class="p">])[</span><span class="s1">&#39;x&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">trange</span><span class="p">,</span><span class="n">data_s</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">trange</span><span class="p">,</span><span class="n">a_min_loc_s</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">trange</span><span class="o">+</span><span class="n">a_min_loc_s</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">trange</span><span class="p">,</span><span class="n">a_min_loc_wrong</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">trange</span><span class="o">+</span><span class="n">a_min_loc_wrong</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;module &#39;matplotlib.pyplot&#39; from &#39;/opt/anaconda3/lib/python3.9/site-packages/matplotlib/pyplot.py&#39;&gt;
</pre></div>
</div>
<img alt="_images/Topic6a_Bayes_95_1.png" src="_images/Topic6a_Bayes_95_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">a_min_loc_wrong</span><span class="p">,</span><span class="n">a_min_loc_s</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(array([ 0.07166517, -0.00599876]), array([ 0.06788174, -0.00249711]))
</pre></div>
</div>
</div>
</div>
<p>Although the lines look similar, we see that weighting the data with the correct noise model gave a much better fit in terms of being much close to the true value.  Furthermore, we also know that it would make no sense to report undercertainties on our least squares fit, as the errors only make sense when you know <span class="math notranslate nohighlight">\(\sigma(t)\)</span>.</p>
</section>
<section id="summary">
<h2>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">#</a></h2>
<p>Bayesian inference is argueably the most important framework in which to understand data, whether scientific or otherwise.  With very little work, we could understand a lot of seemingly complicated statistical tools as just examples of Bayes‚Äô theorem in special cases. Most important, the concept of uncertainty is essential when trying to understand the world: our knownledge isn‚Äôt binary, but comes with levels of confidence.  Bayes‚Äô tells us how to make that uncertainty precise and do work for us.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="Topic5_data_analysis.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Topic 5: Intro to Data Analysis</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="Topic6b_ML.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Topic 6b: Intro to Machine Learning</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By The Jupyter Book Community<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>